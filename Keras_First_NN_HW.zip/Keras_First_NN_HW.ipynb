{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set (Internet Access needed)\n",
    "\n",
    "##url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('pima-indians-diabetes.data', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5</td>\n",
       "      <td>99</td>\n",
       "      <td>74</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.203</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>11</td>\n",
       "      <td>85</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.300</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>37</td>\n",
       "      <td>148</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.605</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "65                5                      99              74              27   \n",
       "559              11                      85              74               0   \n",
       "311               0                     106              70              37   \n",
       "502               6                       0              68              41   \n",
       "18                1                     103              30              38   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "65         0  29.0              0.203   32             0  \n",
       "559        0  30.1              0.300   35             0  \n",
       "311      148  39.4              0.605   22             0  \n",
       "502        0  39.0              0.727   41             1  \n",
       "18        83  43.3              0.183   33             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.776\n",
      "roc-auc is 0.831\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "#O método \"predict_classes\" não funciona nas versões do Keras superior a 2.5 \n",
    "\n",
    "# A indicação da correção se encontra em https://keras.rstudio.com/reference/predict_proba.html#details. \n",
    "\n",
    "# usar: \n",
    "# y_pred_class_nn_1 = model_1.predict(X_test_norm)\n",
    "# y_pred_class_nn_1 = (y_pred_prob_nn_1 > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.51292693,  0.05718153, -1.00845664, ...,  1.31568163,\n",
       "         0.10454166, -0.59587928],\n",
       "       [ 0.67241274,  0.40388219,  0.58160947, ...,  1.84369824,\n",
       "        -0.72769273,  1.11554662],\n",
       "       [ 0.0797429 , -0.1949644 ,  0.18409294, ..., -0.38427428,\n",
       "        -0.32042909,  1.11554662],\n",
       "       ...,\n",
       "       [ 1.26508257,  2.10586723,  0.48223034, ...,  2.06263196,\n",
       "        -1.02576249,  0.85883273],\n",
       "       [ 0.0797429 ,  1.0972835 ,  0.33316164, ...,  2.11414577,\n",
       "        -0.72769273, -0.08245151],\n",
       "       [-0.51292693,  0.5614734 ,  0.33316164, ..., -0.80926326,\n",
       "        -0.93722691, -0.33916539]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)\n",
    "X_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-12 00:42:36.412972: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-12 00:42:36.413064: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-12 00:42:36.413128: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Student): /proc/driver/nvidia/version does not exist\n",
      "2022-01-12 00:42:36.413863: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "\n",
    "São 121 parâmetros pois a camada de entrada possui 8 nós, a camada oculta possui 12 nós e recebe 8 pesos da camada anterior totalizando 96 parâmetros, 12 parâmetros são os bias de cada nós da camada oculta e a camada de saida possui apenas 1 nó que recebe 12 pesos da camada oculta e um bias. Sendo assim temos um total de 121 parâmetros.   \n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 2s 15ms/step - loss: 0.8916 - accuracy: 0.6163 - val_loss: 0.9386 - val_accuracy: 0.6250\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8760 - accuracy: 0.6233 - val_loss: 0.9225 - val_accuracy: 0.6302\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8612 - accuracy: 0.6233 - val_loss: 0.9073 - val_accuracy: 0.6302\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8472 - accuracy: 0.6267 - val_loss: 0.8928 - val_accuracy: 0.6354\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8339 - accuracy: 0.6267 - val_loss: 0.8791 - val_accuracy: 0.6406\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8212 - accuracy: 0.6285 - val_loss: 0.8660 - val_accuracy: 0.6406\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8092 - accuracy: 0.6285 - val_loss: 0.8535 - val_accuracy: 0.6406\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7977 - accuracy: 0.6302 - val_loss: 0.8415 - val_accuracy: 0.6406\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7868 - accuracy: 0.6337 - val_loss: 0.8302 - val_accuracy: 0.6406\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7765 - accuracy: 0.6354 - val_loss: 0.8193 - val_accuracy: 0.6458\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7665 - accuracy: 0.6354 - val_loss: 0.8089 - val_accuracy: 0.6458\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7571 - accuracy: 0.6354 - val_loss: 0.7990 - val_accuracy: 0.6510\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7482 - accuracy: 0.6337 - val_loss: 0.7896 - val_accuracy: 0.6615\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7396 - accuracy: 0.6354 - val_loss: 0.7806 - val_accuracy: 0.6667\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7315 - accuracy: 0.6354 - val_loss: 0.7720 - val_accuracy: 0.6771\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7237 - accuracy: 0.6389 - val_loss: 0.7639 - val_accuracy: 0.6823\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7162 - accuracy: 0.6406 - val_loss: 0.7560 - val_accuracy: 0.6823\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7091 - accuracy: 0.6406 - val_loss: 0.7485 - val_accuracy: 0.6927\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7023 - accuracy: 0.6406 - val_loss: 0.7413 - val_accuracy: 0.6979\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6957 - accuracy: 0.6424 - val_loss: 0.7344 - val_accuracy: 0.6979\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.6424 - val_loss: 0.7277 - val_accuracy: 0.6979\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6833 - accuracy: 0.6476 - val_loss: 0.7212 - val_accuracy: 0.6979\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.6493 - val_loss: 0.7150 - val_accuracy: 0.6927\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.6510 - val_loss: 0.7090 - val_accuracy: 0.6927\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.6562 - val_loss: 0.7033 - val_accuracy: 0.6927\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.6580 - val_loss: 0.6977 - val_accuracy: 0.6927\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.6580 - val_loss: 0.6924 - val_accuracy: 0.6927\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6562 - val_loss: 0.6873 - val_accuracy: 0.6927\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.6510 - val_loss: 0.6823 - val_accuracy: 0.6927\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.6528 - val_loss: 0.6775 - val_accuracy: 0.6927\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.6528 - val_loss: 0.6729 - val_accuracy: 0.6927\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.6545 - val_loss: 0.6684 - val_accuracy: 0.6979\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 0.6545 - val_loss: 0.6641 - val_accuracy: 0.6979\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.6562 - val_loss: 0.6599 - val_accuracy: 0.6979\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6221 - accuracy: 0.6597 - val_loss: 0.6559 - val_accuracy: 0.6979\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.6632 - val_loss: 0.6520 - val_accuracy: 0.6979\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.6684 - val_loss: 0.6482 - val_accuracy: 0.6979\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6115 - accuracy: 0.6667 - val_loss: 0.6445 - val_accuracy: 0.7031\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6667 - val_loss: 0.6409 - val_accuracy: 0.7031\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.6701 - val_loss: 0.6374 - val_accuracy: 0.6979\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.6736 - val_loss: 0.6341 - val_accuracy: 0.6979\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.6771 - val_loss: 0.6308 - val_accuracy: 0.6979\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.6806 - val_loss: 0.6276 - val_accuracy: 0.6979\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5928 - accuracy: 0.6823 - val_loss: 0.6245 - val_accuracy: 0.6979\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.6806 - val_loss: 0.6214 - val_accuracy: 0.6979\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.6840 - val_loss: 0.6185 - val_accuracy: 0.6979\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.6858 - val_loss: 0.6156 - val_accuracy: 0.6927\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.6892 - val_loss: 0.6127 - val_accuracy: 0.6927\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.6927 - val_loss: 0.6100 - val_accuracy: 0.6927\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.6944 - val_loss: 0.6073 - val_accuracy: 0.6927\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.6962 - val_loss: 0.6047 - val_accuracy: 0.6927\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.6979 - val_loss: 0.6021 - val_accuracy: 0.6927\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.6979 - val_loss: 0.5997 - val_accuracy: 0.6927\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.7014 - val_loss: 0.5973 - val_accuracy: 0.6927\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.7031 - val_loss: 0.5949 - val_accuracy: 0.6979\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.7101 - val_loss: 0.5926 - val_accuracy: 0.6979\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.7188 - val_loss: 0.5904 - val_accuracy: 0.7031\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.7222 - val_loss: 0.5883 - val_accuracy: 0.6979\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7274 - val_loss: 0.5862 - val_accuracy: 0.6979\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.7309 - val_loss: 0.5842 - val_accuracy: 0.6979\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7344 - val_loss: 0.5822 - val_accuracy: 0.7083\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.7378 - val_loss: 0.5802 - val_accuracy: 0.7031\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7396 - val_loss: 0.5783 - val_accuracy: 0.7031\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.7378 - val_loss: 0.5764 - val_accuracy: 0.7031\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7378 - val_loss: 0.5746 - val_accuracy: 0.7031\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7378 - val_loss: 0.5728 - val_accuracy: 0.6979\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7378 - val_loss: 0.5711 - val_accuracy: 0.6979\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7413 - val_loss: 0.5694 - val_accuracy: 0.6979\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7431 - val_loss: 0.5678 - val_accuracy: 0.6979\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7431 - val_loss: 0.5662 - val_accuracy: 0.7031\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5353 - accuracy: 0.7431 - val_loss: 0.5647 - val_accuracy: 0.7031\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.7448 - val_loss: 0.5632 - val_accuracy: 0.7031\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5323 - accuracy: 0.7465 - val_loss: 0.5617 - val_accuracy: 0.7031\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7500 - val_loss: 0.5603 - val_accuracy: 0.7083\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5295 - accuracy: 0.7500 - val_loss: 0.5589 - val_accuracy: 0.7083\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5282 - accuracy: 0.7517 - val_loss: 0.5575 - val_accuracy: 0.7083\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5269 - accuracy: 0.7517 - val_loss: 0.5562 - val_accuracy: 0.7083\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7500 - val_loss: 0.5549 - val_accuracy: 0.7135\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7517 - val_loss: 0.5536 - val_accuracy: 0.7135\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5230 - accuracy: 0.7517 - val_loss: 0.5523 - val_accuracy: 0.7135\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7569 - val_loss: 0.5511 - val_accuracy: 0.7135\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5206 - accuracy: 0.7552 - val_loss: 0.5499 - val_accuracy: 0.7188\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5194 - accuracy: 0.7552 - val_loss: 0.5488 - val_accuracy: 0.7188\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5182 - accuracy: 0.7552 - val_loss: 0.5476 - val_accuracy: 0.7240\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5171 - accuracy: 0.7569 - val_loss: 0.5465 - val_accuracy: 0.7240\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5160 - accuracy: 0.7569 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5149 - accuracy: 0.7569 - val_loss: 0.5444 - val_accuracy: 0.7292\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7552 - val_loss: 0.5433 - val_accuracy: 0.7292\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.7552 - val_loss: 0.5423 - val_accuracy: 0.7292\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5117 - accuracy: 0.7569 - val_loss: 0.5413 - val_accuracy: 0.7240\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5107 - accuracy: 0.7569 - val_loss: 0.5403 - val_accuracy: 0.7240\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5097 - accuracy: 0.7569 - val_loss: 0.5393 - val_accuracy: 0.7240\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5087 - accuracy: 0.7569 - val_loss: 0.5384 - val_accuracy: 0.7344\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.7604 - val_loss: 0.5375 - val_accuracy: 0.7292\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.7604 - val_loss: 0.5366 - val_accuracy: 0.7292\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5058 - accuracy: 0.7604 - val_loss: 0.5357 - val_accuracy: 0.7292\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5049 - accuracy: 0.7604 - val_loss: 0.5348 - val_accuracy: 0.7292\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.7604 - val_loss: 0.5339 - val_accuracy: 0.7292\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7604 - val_loss: 0.5331 - val_accuracy: 0.7240\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7622 - val_loss: 0.5323 - val_accuracy: 0.7292\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7622 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5004 - accuracy: 0.7639 - val_loss: 0.5307 - val_accuracy: 0.7344\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.7639 - val_loss: 0.5299 - val_accuracy: 0.7344\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7639 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7639 - val_loss: 0.5283 - val_accuracy: 0.7344\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.7656 - val_loss: 0.5276 - val_accuracy: 0.7344\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.7656 - val_loss: 0.5269 - val_accuracy: 0.7344\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4955 - accuracy: 0.7639 - val_loss: 0.5262 - val_accuracy: 0.7344\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4947 - accuracy: 0.7656 - val_loss: 0.5255 - val_accuracy: 0.7344\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4939 - accuracy: 0.7639 - val_loss: 0.5248 - val_accuracy: 0.7396\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.7639 - val_loss: 0.5241 - val_accuracy: 0.7396\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.7639 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.7639 - val_loss: 0.5229 - val_accuracy: 0.7396\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.7639 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7656 - val_loss: 0.5217 - val_accuracy: 0.7396\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4896 - accuracy: 0.7656 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7639 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7656 - val_loss: 0.5200 - val_accuracy: 0.7448\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.7656 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7691 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7691 - val_loss: 0.5184 - val_accuracy: 0.7396\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.7708 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4851 - accuracy: 0.7726 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7708 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4839 - accuracy: 0.7726 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4833 - accuracy: 0.7726 - val_loss: 0.5160 - val_accuracy: 0.7396\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4827 - accuracy: 0.7760 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4821 - accuracy: 0.7760 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.7760 - val_loss: 0.5146 - val_accuracy: 0.7396\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7778 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7795 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7795 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.7795 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7830 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.7812 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.7812 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7812 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7795 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4762 - accuracy: 0.7795 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4757 - accuracy: 0.7795 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7795 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.7795 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7795 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7795 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7795 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7795 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7760 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7760 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7760 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7760 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7760 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7743 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4699 - accuracy: 0.7743 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7743 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7743 - val_loss: 0.5062 - val_accuracy: 0.7552\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7778 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7778 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7795 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.7795 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.5050 - val_accuracy: 0.7552\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.5045 - val_accuracy: 0.7552\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.5043 - val_accuracy: 0.7552\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.7812 - val_loss: 0.5041 - val_accuracy: 0.7552\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.5039 - val_accuracy: 0.7552\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.5035 - val_accuracy: 0.7500\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7830 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7830 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7830 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7830 - val_loss: 0.5025 - val_accuracy: 0.7552\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7830 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7830 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7795 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7795 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4989 - val_accuracy: 0.7708\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "#y_pred_class_nn_1 = (y_pred_class_nn_1 > 0.5).astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4282342 ],\n",
       "       [0.5928198 ],\n",
       "       [0.4210045 ],\n",
       "       [0.3299508 ],\n",
       "       [0.22324634],\n",
       "       [0.45648468],\n",
       "       [0.06513485],\n",
       "       [0.53343856],\n",
       "       [0.7854638 ],\n",
       "       [0.3497211 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.771\n",
      "roc-auc is 0.815\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6d39f43670>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7778 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7778 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.7778 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7778 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7778 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7778 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7778 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7778 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.7778 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7778 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7795 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7795 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7778 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7812 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7795 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7795 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7795 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7795 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7795 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7795 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7795 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7656\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7656\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7778 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7743 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7760 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7760 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4464 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7778 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7778 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7778 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7778 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7778 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7778 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7778 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7795 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7778 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7795 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.7830 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7812 - val_loss: 0.4981 - val_accuracy: 0.7656\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7812 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7830 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7656\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7830 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7830 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7830 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7830 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7830 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7830 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7830 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7847 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7812 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7847 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7847 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7830 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7830 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7830 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7830 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7830 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7830 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7830 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7830 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7830 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7830 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7830 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7830 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7830 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7830 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7830 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7830 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7830 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7830 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7830 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7830 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7830 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7830 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7830 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7830 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7830 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7830 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7812 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7812 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7830 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7830 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7830 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7830 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7830 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7830 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7830 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7830 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7795 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7830 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7795 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7795 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7830 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7812 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7847 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7830 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7830 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7830 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7830 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7847 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.5004 - val_accuracy: 0.7500\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.5005 - val_accuracy: 0.7500\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7500\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7552\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7552\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7847 - val_loss: 0.5006 - val_accuracy: 0.7552\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7552\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.5006 - val_accuracy: 0.7552\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7865 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7899 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7899 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7899 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7882 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7847 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7882 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7865 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7847 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7865 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7847 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7865 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7865 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7847 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7847 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7847 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7865 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7847 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7882 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7882 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.5009 - val_accuracy: 0.7760\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7760\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7934 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7917 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7917 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7865 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7917 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7917 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7899 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7899 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7882 - val_loss: 0.5007 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6d396f2910>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Possivelmente 400 epocas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Now it's your turn.  Do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(6, input_dim=8, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "learning_rate = .003\n",
    "n_epochs = 1500\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.7990 - accuracy: 0.4340 - val_loss: 0.7770 - val_accuracy: 0.4219\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7882 - accuracy: 0.4531 - val_loss: 0.7682 - val_accuracy: 0.4583\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7784 - accuracy: 0.4653 - val_loss: 0.7603 - val_accuracy: 0.4740\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7695 - accuracy: 0.4740 - val_loss: 0.7530 - val_accuracy: 0.4844\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7614 - accuracy: 0.4844 - val_loss: 0.7464 - val_accuracy: 0.4896\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7539 - accuracy: 0.4878 - val_loss: 0.7405 - val_accuracy: 0.5052\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7470 - accuracy: 0.4983 - val_loss: 0.7349 - val_accuracy: 0.5104\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7406 - accuracy: 0.5000 - val_loss: 0.7298 - val_accuracy: 0.5156\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7347 - accuracy: 0.5087 - val_loss: 0.7251 - val_accuracy: 0.5156\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7293 - accuracy: 0.5260 - val_loss: 0.7207 - val_accuracy: 0.5417\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7242 - accuracy: 0.5382 - val_loss: 0.7165 - val_accuracy: 0.5469\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7194 - accuracy: 0.5451 - val_loss: 0.7126 - val_accuracy: 0.5521\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7150 - accuracy: 0.5521 - val_loss: 0.7089 - val_accuracy: 0.5521\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7108 - accuracy: 0.5573 - val_loss: 0.7055 - val_accuracy: 0.5677\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7069 - accuracy: 0.5660 - val_loss: 0.7023 - val_accuracy: 0.5677\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.5799 - val_loss: 0.6993 - val_accuracy: 0.5677\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6997 - accuracy: 0.5816 - val_loss: 0.6964 - val_accuracy: 0.5781\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6964 - accuracy: 0.5885 - val_loss: 0.6937 - val_accuracy: 0.5833\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.5903 - val_loss: 0.6912 - val_accuracy: 0.5833\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5972 - val_loss: 0.6888 - val_accuracy: 0.5990\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.6024 - val_loss: 0.6866 - val_accuracy: 0.6094\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.6111 - val_loss: 0.6844 - val_accuracy: 0.6198\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.6215 - val_loss: 0.6823 - val_accuracy: 0.6198\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.6198 - val_loss: 0.6803 - val_accuracy: 0.6302\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.6337 - val_loss: 0.6783 - val_accuracy: 0.6198\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.6389 - val_loss: 0.6764 - val_accuracy: 0.6198\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.6389 - val_loss: 0.6747 - val_accuracy: 0.6146\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.6424 - val_loss: 0.6729 - val_accuracy: 0.6146\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.6441 - val_loss: 0.6713 - val_accuracy: 0.6146\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.6441 - val_loss: 0.6697 - val_accuracy: 0.6198\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.6441 - val_loss: 0.6682 - val_accuracy: 0.6250\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.6441 - val_loss: 0.6668 - val_accuracy: 0.6250\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.6458 - val_loss: 0.6655 - val_accuracy: 0.6198\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6616 - accuracy: 0.6476 - val_loss: 0.6641 - val_accuracy: 0.6198\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.6476 - val_loss: 0.6629 - val_accuracy: 0.6198\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6586 - accuracy: 0.6476 - val_loss: 0.6616 - val_accuracy: 0.6198\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.6458 - val_loss: 0.6604 - val_accuracy: 0.6198\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6558 - accuracy: 0.6493 - val_loss: 0.6593 - val_accuracy: 0.6198\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.6493 - val_loss: 0.6582 - val_accuracy: 0.6198\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6532 - accuracy: 0.6493 - val_loss: 0.6571 - val_accuracy: 0.6198\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6520 - accuracy: 0.6493 - val_loss: 0.6561 - val_accuracy: 0.6198\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6508 - accuracy: 0.6510 - val_loss: 0.6550 - val_accuracy: 0.6198\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6540 - val_accuracy: 0.6250\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.6528 - val_loss: 0.6530 - val_accuracy: 0.6250\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.6528 - val_loss: 0.6520 - val_accuracy: 0.6302\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.6528 - val_loss: 0.6510 - val_accuracy: 0.6302\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.6528 - val_loss: 0.6500 - val_accuracy: 0.6354\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.6528 - val_loss: 0.6490 - val_accuracy: 0.6354\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.6528 - val_loss: 0.6480 - val_accuracy: 0.6354\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6528 - val_loss: 0.6470 - val_accuracy: 0.6354\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.6528 - val_loss: 0.6460 - val_accuracy: 0.6354\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.6528 - val_loss: 0.6450 - val_accuracy: 0.6354\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.6528 - val_loss: 0.6441 - val_accuracy: 0.6354\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6366 - accuracy: 0.6528 - val_loss: 0.6432 - val_accuracy: 0.6354\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.6528 - val_loss: 0.6422 - val_accuracy: 0.6354\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6341 - accuracy: 0.6528 - val_loss: 0.6413 - val_accuracy: 0.6354\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6328 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6354\n",
      "Epoch 58/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.6493 - val_loss: 0.6395 - val_accuracy: 0.6354\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.6476 - val_loss: 0.6386 - val_accuracy: 0.6354\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.6476 - val_loss: 0.6377 - val_accuracy: 0.6354\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.6476 - val_loss: 0.6369 - val_accuracy: 0.6354\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.6476 - val_loss: 0.6360 - val_accuracy: 0.6354\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6254 - accuracy: 0.6476 - val_loss: 0.6352 - val_accuracy: 0.6354\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6243 - accuracy: 0.6458 - val_loss: 0.6344 - val_accuracy: 0.6354\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.6458 - val_loss: 0.6336 - val_accuracy: 0.6354\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.6458 - val_loss: 0.6328 - val_accuracy: 0.6354\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6209 - accuracy: 0.6458 - val_loss: 0.6321 - val_accuracy: 0.6354\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.6458 - val_loss: 0.6314 - val_accuracy: 0.6354\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.6458 - val_loss: 0.6307 - val_accuracy: 0.6354\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.6458 - val_loss: 0.6300 - val_accuracy: 0.6354\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.6458 - val_loss: 0.6293 - val_accuracy: 0.6354\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.6458 - val_loss: 0.6286 - val_accuracy: 0.6354\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.6458 - val_loss: 0.6279 - val_accuracy: 0.6354\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.6493 - val_loss: 0.6272 - val_accuracy: 0.6354\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.6493 - val_loss: 0.6265 - val_accuracy: 0.6354\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6118 - accuracy: 0.6493 - val_loss: 0.6259 - val_accuracy: 0.6354\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.6493 - val_loss: 0.6252 - val_accuracy: 0.6354\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.6493 - val_loss: 0.6245 - val_accuracy: 0.6354\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6528 - val_loss: 0.6238 - val_accuracy: 0.6354\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.6545 - val_loss: 0.6231 - val_accuracy: 0.6354\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.6545 - val_loss: 0.6224 - val_accuracy: 0.6354\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.6545 - val_loss: 0.6218 - val_accuracy: 0.6354\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.6545 - val_loss: 0.6211 - val_accuracy: 0.6354\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.6545 - val_loss: 0.6205 - val_accuracy: 0.6354\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.6545 - val_loss: 0.6198 - val_accuracy: 0.6354\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6013 - accuracy: 0.6528 - val_loss: 0.6192 - val_accuracy: 0.6354\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.6510 - val_loss: 0.6185 - val_accuracy: 0.6406\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.6510 - val_loss: 0.6179 - val_accuracy: 0.6406\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.6510 - val_loss: 0.6173 - val_accuracy: 0.6406\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5973 - accuracy: 0.6528 - val_loss: 0.6167 - val_accuracy: 0.6406\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.6528 - val_loss: 0.6161 - val_accuracy: 0.6406\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.6528 - val_loss: 0.6155 - val_accuracy: 0.6406\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.6528 - val_loss: 0.6149 - val_accuracy: 0.6406\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.6528 - val_loss: 0.6143 - val_accuracy: 0.6406\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5926 - accuracy: 0.6528 - val_loss: 0.6138 - val_accuracy: 0.6354\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.6528 - val_loss: 0.6132 - val_accuracy: 0.6354\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5908 - accuracy: 0.6545 - val_loss: 0.6126 - val_accuracy: 0.6354\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.6545 - val_loss: 0.6121 - val_accuracy: 0.6354\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.6545 - val_loss: 0.6115 - val_accuracy: 0.6354\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.6545 - val_loss: 0.6110 - val_accuracy: 0.6354\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.6545 - val_loss: 0.6104 - val_accuracy: 0.6354\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.6545 - val_loss: 0.6099 - val_accuracy: 0.6354\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.6545 - val_loss: 0.6094 - val_accuracy: 0.6354\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.6545 - val_loss: 0.6089 - val_accuracy: 0.6354\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5842 - accuracy: 0.6562 - val_loss: 0.6084 - val_accuracy: 0.6354\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.6562 - val_loss: 0.6079 - val_accuracy: 0.6354\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5826 - accuracy: 0.6562 - val_loss: 0.6074 - val_accuracy: 0.6354\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 0.6562 - val_loss: 0.6069 - val_accuracy: 0.6354\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.6562 - val_loss: 0.6063 - val_accuracy: 0.6354\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5803 - accuracy: 0.6562 - val_loss: 0.6059 - val_accuracy: 0.6354\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.6562 - val_loss: 0.6054 - val_accuracy: 0.6354\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.6562 - val_loss: 0.6049 - val_accuracy: 0.6354\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.6562 - val_loss: 0.6044 - val_accuracy: 0.6354\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.6562 - val_loss: 0.6039 - val_accuracy: 0.6354\n",
      "Epoch 115/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.6562 - val_loss: 0.6034 - val_accuracy: 0.6354\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.6562 - val_loss: 0.6030 - val_accuracy: 0.6354\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.6562 - val_loss: 0.6025 - val_accuracy: 0.6354\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.6580 - val_loss: 0.6020 - val_accuracy: 0.6354\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.6580 - val_loss: 0.6015 - val_accuracy: 0.6354\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.6580 - val_loss: 0.6011 - val_accuracy: 0.6354\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.6580 - val_loss: 0.6006 - val_accuracy: 0.6354\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.6580 - val_loss: 0.6002 - val_accuracy: 0.6354\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.6580 - val_loss: 0.5997 - val_accuracy: 0.6354\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.6580 - val_loss: 0.5992 - val_accuracy: 0.6354\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.6580 - val_loss: 0.5988 - val_accuracy: 0.6354\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.6580 - val_loss: 0.5984 - val_accuracy: 0.6354\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.6580 - val_loss: 0.5979 - val_accuracy: 0.6354\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.6580 - val_loss: 0.5975 - val_accuracy: 0.6354\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.6580 - val_loss: 0.5970 - val_accuracy: 0.6354\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5667 - accuracy: 0.6597 - val_loss: 0.5966 - val_accuracy: 0.6354\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.6597 - val_loss: 0.5962 - val_accuracy: 0.6354\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.6597 - val_loss: 0.5957 - val_accuracy: 0.6354\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.6597 - val_loss: 0.5953 - val_accuracy: 0.6354\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.6597 - val_loss: 0.5949 - val_accuracy: 0.6354\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.6597 - val_loss: 0.5945 - val_accuracy: 0.6354\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.6597 - val_loss: 0.5940 - val_accuracy: 0.6354\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.6597 - val_loss: 0.5936 - val_accuracy: 0.6354\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.6615 - val_loss: 0.5932 - val_accuracy: 0.6354\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.6615 - val_loss: 0.5927 - val_accuracy: 0.6354\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.6615 - val_loss: 0.5923 - val_accuracy: 0.6354\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.6615 - val_loss: 0.5919 - val_accuracy: 0.6354\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.6615 - val_loss: 0.5915 - val_accuracy: 0.6354\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5590 - accuracy: 0.6615 - val_loss: 0.5910 - val_accuracy: 0.6354\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5584 - accuracy: 0.6615 - val_loss: 0.5906 - val_accuracy: 0.6354\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5578 - accuracy: 0.6615 - val_loss: 0.5902 - val_accuracy: 0.6354\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5572 - accuracy: 0.6615 - val_loss: 0.5898 - val_accuracy: 0.6354\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.6632 - val_loss: 0.5894 - val_accuracy: 0.6354\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.6632 - val_loss: 0.5890 - val_accuracy: 0.6354\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5555 - accuracy: 0.6632 - val_loss: 0.5886 - val_accuracy: 0.6354\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.6632 - val_loss: 0.5882 - val_accuracy: 0.6354\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.6632 - val_loss: 0.5878 - val_accuracy: 0.6354\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.6632 - val_loss: 0.5874 - val_accuracy: 0.6354\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.6632 - val_loss: 0.5870 - val_accuracy: 0.6354\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.6632 - val_loss: 0.5866 - val_accuracy: 0.6354\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.6632 - val_loss: 0.5862 - val_accuracy: 0.6354\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.6649 - val_loss: 0.5858 - val_accuracy: 0.6354\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5510 - accuracy: 0.6649 - val_loss: 0.5854 - val_accuracy: 0.6354\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5505 - accuracy: 0.6649 - val_loss: 0.5851 - val_accuracy: 0.6354\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5499 - accuracy: 0.6649 - val_loss: 0.5847 - val_accuracy: 0.6354\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5493 - accuracy: 0.6649 - val_loss: 0.5843 - val_accuracy: 0.6354\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5488 - accuracy: 0.6649 - val_loss: 0.5839 - val_accuracy: 0.6354\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5483 - accuracy: 0.6649 - val_loss: 0.5835 - val_accuracy: 0.6354\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5478 - accuracy: 0.6632 - val_loss: 0.5832 - val_accuracy: 0.6354\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.6632 - val_loss: 0.5828 - val_accuracy: 0.6354\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5467 - accuracy: 0.6632 - val_loss: 0.5824 - val_accuracy: 0.6354\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.6632 - val_loss: 0.5821 - val_accuracy: 0.6354\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.6632 - val_loss: 0.5817 - val_accuracy: 0.6354\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.6597 - val_loss: 0.5814 - val_accuracy: 0.6354\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5446 - accuracy: 0.6597 - val_loss: 0.5810 - val_accuracy: 0.6354\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5441 - accuracy: 0.6615 - val_loss: 0.5806 - val_accuracy: 0.6354\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.6615 - val_loss: 0.5803 - val_accuracy: 0.6354\n",
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5431 - accuracy: 0.6615 - val_loss: 0.5799 - val_accuracy: 0.6354\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5426 - accuracy: 0.6615 - val_loss: 0.5796 - val_accuracy: 0.6354\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.6615 - val_loss: 0.5793 - val_accuracy: 0.6354\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.6615 - val_loss: 0.5789 - val_accuracy: 0.6354\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.6615 - val_loss: 0.5786 - val_accuracy: 0.6354\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.6615 - val_loss: 0.5782 - val_accuracy: 0.6354\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.6615 - val_loss: 0.5779 - val_accuracy: 0.6354\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.6615 - val_loss: 0.5775 - val_accuracy: 0.6354\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.6615 - val_loss: 0.5772 - val_accuracy: 0.6354\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.6632 - val_loss: 0.5768 - val_accuracy: 0.6354\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.6632 - val_loss: 0.5765 - val_accuracy: 0.6354\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.6649 - val_loss: 0.5761 - val_accuracy: 0.6354\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.6667 - val_loss: 0.5758 - val_accuracy: 0.6354\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.6667 - val_loss: 0.5755 - val_accuracy: 0.6354\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.6667 - val_loss: 0.5751 - val_accuracy: 0.6354\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.6684 - val_loss: 0.5748 - val_accuracy: 0.6354\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.6684 - val_loss: 0.5744 - val_accuracy: 0.6354\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.6684 - val_loss: 0.5741 - val_accuracy: 0.6354\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.6684 - val_loss: 0.5737 - val_accuracy: 0.6354\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.6684 - val_loss: 0.5734 - val_accuracy: 0.6354\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.6684 - val_loss: 0.5731 - val_accuracy: 0.6354\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.6684 - val_loss: 0.5727 - val_accuracy: 0.6354\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.6684 - val_loss: 0.5724 - val_accuracy: 0.6354\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.6684 - val_loss: 0.5721 - val_accuracy: 0.6354\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.6684 - val_loss: 0.5718 - val_accuracy: 0.6354\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.6684 - val_loss: 0.5715 - val_accuracy: 0.6354\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.6701 - val_loss: 0.5712 - val_accuracy: 0.6354\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.6701 - val_loss: 0.5709 - val_accuracy: 0.6354\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.6701 - val_loss: 0.5705 - val_accuracy: 0.6406\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.6701 - val_loss: 0.5702 - val_accuracy: 0.6406\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.6701 - val_loss: 0.5699 - val_accuracy: 0.6354\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.6701 - val_loss: 0.5696 - val_accuracy: 0.6406\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.6701 - val_loss: 0.5693 - val_accuracy: 0.6406\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.6701 - val_loss: 0.5690 - val_accuracy: 0.6406\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.6736 - val_loss: 0.5687 - val_accuracy: 0.6406\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.6736 - val_loss: 0.5684 - val_accuracy: 0.6406\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.6736 - val_loss: 0.5681 - val_accuracy: 0.6406\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.6753 - val_loss: 0.5678 - val_accuracy: 0.6458\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.6753 - val_loss: 0.5675 - val_accuracy: 0.6458\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.6753 - val_loss: 0.5672 - val_accuracy: 0.6458\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.6753 - val_loss: 0.5669 - val_accuracy: 0.6458\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.6753 - val_loss: 0.5667 - val_accuracy: 0.6458\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.6753 - val_loss: 0.5664 - val_accuracy: 0.6458\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.6771 - val_loss: 0.5661 - val_accuracy: 0.6458\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.6771 - val_loss: 0.5658 - val_accuracy: 0.6458\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.6753 - val_loss: 0.5655 - val_accuracy: 0.6458\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.6753 - val_loss: 0.5652 - val_accuracy: 0.6562\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.6771 - val_loss: 0.5649 - val_accuracy: 0.6562\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.6753 - val_loss: 0.5646 - val_accuracy: 0.6562\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.6771 - val_loss: 0.5643 - val_accuracy: 0.6562\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.6771 - val_loss: 0.5640 - val_accuracy: 0.6562\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.6788 - val_loss: 0.5637 - val_accuracy: 0.6615\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.6788 - val_loss: 0.5635 - val_accuracy: 0.6615\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.6788 - val_loss: 0.5632 - val_accuracy: 0.6615\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.6771 - val_loss: 0.5629 - val_accuracy: 0.6562\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.6753 - val_loss: 0.5626 - val_accuracy: 0.6562\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.6753 - val_loss: 0.5623 - val_accuracy: 0.6562\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.6753 - val_loss: 0.5621 - val_accuracy: 0.6667\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.6753 - val_loss: 0.5618 - val_accuracy: 0.6667\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.6771 - val_loss: 0.5615 - val_accuracy: 0.6667\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.6788 - val_loss: 0.5612 - val_accuracy: 0.6719\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.6788 - val_loss: 0.5610 - val_accuracy: 0.6719\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.6788 - val_loss: 0.5607 - val_accuracy: 0.6719\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.6806 - val_loss: 0.5604 - val_accuracy: 0.6667\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.6806 - val_loss: 0.5601 - val_accuracy: 0.6667\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.6823 - val_loss: 0.5598 - val_accuracy: 0.6667\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.6823 - val_loss: 0.5596 - val_accuracy: 0.6667\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.6840 - val_loss: 0.5593 - val_accuracy: 0.6667\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.6892 - val_loss: 0.5590 - val_accuracy: 0.6667\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.6910 - val_loss: 0.5587 - val_accuracy: 0.6719\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.6892 - val_loss: 0.5584 - val_accuracy: 0.6719\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.6892 - val_loss: 0.5582 - val_accuracy: 0.6719\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.6910 - val_loss: 0.5579 - val_accuracy: 0.6771\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.6910 - val_loss: 0.5576 - val_accuracy: 0.6771\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.6910 - val_loss: 0.5574 - val_accuracy: 0.6823\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7222 - val_loss: 0.5571 - val_accuracy: 0.7500\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7535 - val_loss: 0.5568 - val_accuracy: 0.7500\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7552 - val_loss: 0.5566 - val_accuracy: 0.7500\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7552 - val_loss: 0.5563 - val_accuracy: 0.7500\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7604 - val_loss: 0.5560 - val_accuracy: 0.7500\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7604 - val_loss: 0.5558 - val_accuracy: 0.7500\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7622 - val_loss: 0.5555 - val_accuracy: 0.7500\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7622 - val_loss: 0.5552 - val_accuracy: 0.7552\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7639 - val_loss: 0.5549 - val_accuracy: 0.7552\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7639 - val_loss: 0.5546 - val_accuracy: 0.7552\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7656 - val_loss: 0.5544 - val_accuracy: 0.7552\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7656 - val_loss: 0.5541 - val_accuracy: 0.7552\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7656 - val_loss: 0.5538 - val_accuracy: 0.7552\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7674 - val_loss: 0.5536 - val_accuracy: 0.7552\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7674 - val_loss: 0.5533 - val_accuracy: 0.7552\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7674 - val_loss: 0.5530 - val_accuracy: 0.7552\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7674 - val_loss: 0.5527 - val_accuracy: 0.7552\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7674 - val_loss: 0.5525 - val_accuracy: 0.7500\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7674 - val_loss: 0.5522 - val_accuracy: 0.7500\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7674 - val_loss: 0.5519 - val_accuracy: 0.7500\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7708 - val_loss: 0.5516 - val_accuracy: 0.7500\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7691 - val_loss: 0.5513 - val_accuracy: 0.7500\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7726 - val_loss: 0.5511 - val_accuracy: 0.7500\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7726 - val_loss: 0.5508 - val_accuracy: 0.7500\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7726 - val_loss: 0.5505 - val_accuracy: 0.7500\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7726 - val_loss: 0.5502 - val_accuracy: 0.7500\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7743 - val_loss: 0.5500 - val_accuracy: 0.7500\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7743 - val_loss: 0.5497 - val_accuracy: 0.7500\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7743 - val_loss: 0.5494 - val_accuracy: 0.7552\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7726 - val_loss: 0.5491 - val_accuracy: 0.7552\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7708 - val_loss: 0.5488 - val_accuracy: 0.7552\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7708 - val_loss: 0.5485 - val_accuracy: 0.7552\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7726 - val_loss: 0.5482 - val_accuracy: 0.7552\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7726 - val_loss: 0.5479 - val_accuracy: 0.7552\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7708 - val_loss: 0.5476 - val_accuracy: 0.7552\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7708 - val_loss: 0.5474 - val_accuracy: 0.7604\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7708 - val_loss: 0.5471 - val_accuracy: 0.7604\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7708 - val_loss: 0.5468 - val_accuracy: 0.7604\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7726 - val_loss: 0.5465 - val_accuracy: 0.7604\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7726 - val_loss: 0.5462 - val_accuracy: 0.7604\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7726 - val_loss: 0.5459 - val_accuracy: 0.7656\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.7726 - val_loss: 0.5456 - val_accuracy: 0.7656\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7726 - val_loss: 0.5454 - val_accuracy: 0.7656\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7708 - val_loss: 0.5451 - val_accuracy: 0.7656\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7708 - val_loss: 0.5448 - val_accuracy: 0.7656\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7708 - val_loss: 0.5445 - val_accuracy: 0.7656\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7708 - val_loss: 0.5443 - val_accuracy: 0.7656\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7708 - val_loss: 0.5440 - val_accuracy: 0.7656\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7708 - val_loss: 0.5437 - val_accuracy: 0.7656\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7708 - val_loss: 0.5435 - val_accuracy: 0.7656\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7708 - val_loss: 0.5432 - val_accuracy: 0.7656\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7708 - val_loss: 0.5429 - val_accuracy: 0.7604\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7708 - val_loss: 0.5426 - val_accuracy: 0.7604\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7726 - val_loss: 0.5424 - val_accuracy: 0.7604\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7743 - val_loss: 0.5421 - val_accuracy: 0.7604\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7726 - val_loss: 0.5418 - val_accuracy: 0.7604\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7726 - val_loss: 0.5416 - val_accuracy: 0.7656\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7743 - val_loss: 0.5413 - val_accuracy: 0.7656\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7743 - val_loss: 0.5411 - val_accuracy: 0.7656\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7743 - val_loss: 0.5408 - val_accuracy: 0.7656\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7726 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7743 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7743 - val_loss: 0.5401 - val_accuracy: 0.7604\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7760 - val_loss: 0.5398 - val_accuracy: 0.7604\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7760 - val_loss: 0.5396 - val_accuracy: 0.7604\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7760 - val_loss: 0.5393 - val_accuracy: 0.7656\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7743 - val_loss: 0.5391 - val_accuracy: 0.7656\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4897 - accuracy: 0.7743 - val_loss: 0.5389 - val_accuracy: 0.7656\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7743 - val_loss: 0.5386 - val_accuracy: 0.7656\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4892 - accuracy: 0.7743 - val_loss: 0.5384 - val_accuracy: 0.7656\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.7743 - val_loss: 0.5382 - val_accuracy: 0.7656\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7743 - val_loss: 0.5380 - val_accuracy: 0.7656\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7726 - val_loss: 0.5378 - val_accuracy: 0.7656\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7726 - val_loss: 0.5376 - val_accuracy: 0.7656\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7726 - val_loss: 0.5374 - val_accuracy: 0.7604\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7726 - val_loss: 0.5372 - val_accuracy: 0.7604\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7726 - val_loss: 0.5370 - val_accuracy: 0.7604\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7726 - val_loss: 0.5367 - val_accuracy: 0.7604\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7726 - val_loss: 0.5365 - val_accuracy: 0.7656\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7726 - val_loss: 0.5363 - val_accuracy: 0.7656\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7726 - val_loss: 0.5361 - val_accuracy: 0.7656\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7726 - val_loss: 0.5359 - val_accuracy: 0.7656\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7726 - val_loss: 0.5357 - val_accuracy: 0.7656\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7743 - val_loss: 0.5355 - val_accuracy: 0.7656\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7743 - val_loss: 0.5354 - val_accuracy: 0.7656\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7743 - val_loss: 0.5352 - val_accuracy: 0.7656\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7743 - val_loss: 0.5350 - val_accuracy: 0.7656\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7743 - val_loss: 0.5348 - val_accuracy: 0.7656\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7743 - val_loss: 0.5347 - val_accuracy: 0.7656\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7743 - val_loss: 0.5345 - val_accuracy: 0.7656\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7743 - val_loss: 0.5343 - val_accuracy: 0.7656\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7743 - val_loss: 0.5341 - val_accuracy: 0.7656\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7743 - val_loss: 0.5340 - val_accuracy: 0.7656\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7743 - val_loss: 0.5338 - val_accuracy: 0.7656\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7726 - val_loss: 0.5336 - val_accuracy: 0.7656\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7726 - val_loss: 0.5334 - val_accuracy: 0.7656\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7726 - val_loss: 0.5333 - val_accuracy: 0.7656\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7726 - val_loss: 0.5331 - val_accuracy: 0.7708\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7726 - val_loss: 0.5329 - val_accuracy: 0.7708\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7743 - val_loss: 0.5327 - val_accuracy: 0.7656\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7726 - val_loss: 0.5325 - val_accuracy: 0.7656\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7760 - val_loss: 0.5324 - val_accuracy: 0.7656\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7743 - val_loss: 0.5322 - val_accuracy: 0.7656\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7760 - val_loss: 0.5320 - val_accuracy: 0.7656\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7760 - val_loss: 0.5318 - val_accuracy: 0.7656\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7743 - val_loss: 0.5316 - val_accuracy: 0.7656\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7760 - val_loss: 0.5314 - val_accuracy: 0.7656\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7778 - val_loss: 0.5313 - val_accuracy: 0.7656\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7778 - val_loss: 0.5311 - val_accuracy: 0.7656\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7795 - val_loss: 0.5309 - val_accuracy: 0.7656\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7795 - val_loss: 0.5307 - val_accuracy: 0.7656\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7795 - val_loss: 0.5305 - val_accuracy: 0.7656\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7795 - val_loss: 0.5304 - val_accuracy: 0.7656\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7795 - val_loss: 0.5302 - val_accuracy: 0.7656\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.7795 - val_loss: 0.5300 - val_accuracy: 0.7656\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7795 - val_loss: 0.5298 - val_accuracy: 0.7656\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7795 - val_loss: 0.5296 - val_accuracy: 0.7656\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7795 - val_loss: 0.5295 - val_accuracy: 0.7656\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7795 - val_loss: 0.5293 - val_accuracy: 0.7656\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7795 - val_loss: 0.5291 - val_accuracy: 0.7656\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7778 - val_loss: 0.5289 - val_accuracy: 0.7708\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7778 - val_loss: 0.5287 - val_accuracy: 0.7708\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7778 - val_loss: 0.5286 - val_accuracy: 0.7708\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7778 - val_loss: 0.5284 - val_accuracy: 0.7708\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7778 - val_loss: 0.5282 - val_accuracy: 0.7708\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7778 - val_loss: 0.5280 - val_accuracy: 0.7708\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7778 - val_loss: 0.5279 - val_accuracy: 0.7708\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4763 - accuracy: 0.7778 - val_loss: 0.5277 - val_accuracy: 0.7708\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4762 - accuracy: 0.7778 - val_loss: 0.5275 - val_accuracy: 0.7760\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7778 - val_loss: 0.5273 - val_accuracy: 0.7812\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7778 - val_loss: 0.5271 - val_accuracy: 0.7812\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7795 - val_loss: 0.5269 - val_accuracy: 0.7812\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7795 - val_loss: 0.5267 - val_accuracy: 0.7812\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7795 - val_loss: 0.5265 - val_accuracy: 0.7812\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7778 - val_loss: 0.5263 - val_accuracy: 0.7812\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7795 - val_loss: 0.5261 - val_accuracy: 0.7812\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7778 - val_loss: 0.5259 - val_accuracy: 0.7812\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7760 - val_loss: 0.5257 - val_accuracy: 0.7812\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7760 - val_loss: 0.5255 - val_accuracy: 0.7812\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7760 - val_loss: 0.5252 - val_accuracy: 0.7760\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7778 - val_loss: 0.5250 - val_accuracy: 0.7760\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7778 - val_loss: 0.5248 - val_accuracy: 0.7760\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7760 - val_loss: 0.5246 - val_accuracy: 0.7760\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7760 - val_loss: 0.5244 - val_accuracy: 0.7760\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7778 - val_loss: 0.5241 - val_accuracy: 0.7760\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7778 - val_loss: 0.5239 - val_accuracy: 0.7760\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7778 - val_loss: 0.5237 - val_accuracy: 0.7760\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7778 - val_loss: 0.5235 - val_accuracy: 0.7760\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7778 - val_loss: 0.5233 - val_accuracy: 0.7760\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7778 - val_loss: 0.5227 - val_accuracy: 0.7708\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7778 - val_loss: 0.5225 - val_accuracy: 0.7708\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7778 - val_loss: 0.5224 - val_accuracy: 0.7708\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7778 - val_loss: 0.5222 - val_accuracy: 0.7656\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7778 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7778 - val_loss: 0.5218 - val_accuracy: 0.7656\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7778 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7795 - val_loss: 0.5214 - val_accuracy: 0.7656\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7795 - val_loss: 0.5212 - val_accuracy: 0.7656\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7795 - val_loss: 0.5210 - val_accuracy: 0.7656\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7795 - val_loss: 0.5208 - val_accuracy: 0.7656\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7795 - val_loss: 0.5206 - val_accuracy: 0.7656\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7795 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7795 - val_loss: 0.5203 - val_accuracy: 0.7604\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7812 - val_loss: 0.5201 - val_accuracy: 0.7604\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7795 - val_loss: 0.5199 - val_accuracy: 0.7604\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7795 - val_loss: 0.5198 - val_accuracy: 0.7604\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7812 - val_loss: 0.5196 - val_accuracy: 0.7604\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7812 - val_loss: 0.5194 - val_accuracy: 0.7604\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.5192 - val_accuracy: 0.7604\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7830 - val_loss: 0.5191 - val_accuracy: 0.7604\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7830 - val_loss: 0.5189 - val_accuracy: 0.7604\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.5188 - val_accuracy: 0.7604\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7604\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.5185 - val_accuracy: 0.7604\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7847 - val_loss: 0.5183 - val_accuracy: 0.7604\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7830 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7830 - val_loss: 0.5180 - val_accuracy: 0.7604\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.5178 - val_accuracy: 0.7604\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.5177 - val_accuracy: 0.7604\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.5176 - val_accuracy: 0.7604\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.5174 - val_accuracy: 0.7604\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7604\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7604\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7604\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7795 - val_loss: 0.5168 - val_accuracy: 0.7604\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7795 - val_loss: 0.5167 - val_accuracy: 0.7604\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7795 - val_loss: 0.5165 - val_accuracy: 0.7604\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7795 - val_loss: 0.5164 - val_accuracy: 0.7604\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.5163 - val_accuracy: 0.7604\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.5162 - val_accuracy: 0.7604\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.5160 - val_accuracy: 0.7604\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.5159 - val_accuracy: 0.7604\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.5158 - val_accuracy: 0.7604\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.5157 - val_accuracy: 0.7604\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.5156 - val_accuracy: 0.7604\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.5154 - val_accuracy: 0.7604\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.5153 - val_accuracy: 0.7604\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7604\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7812 - val_loss: 0.5151 - val_accuracy: 0.7604\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7812 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7812 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7812 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7812 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7812 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7812 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7812 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7812 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7812 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7812 - val_loss: 0.5140 - val_accuracy: 0.7604\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.5137 - val_accuracy: 0.7552\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7812 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.5136 - val_accuracy: 0.7552\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7795 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7795 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7812 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7795 - val_loss: 0.5132 - val_accuracy: 0.7552\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7795 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7795 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7812 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4575 - accuracy: 0.7795 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4561 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7795 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7795 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4553 - accuracy: 0.7795 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.5128 - val_accuracy: 0.7552\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4550 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7760 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.7760 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.7760 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.7760 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.7760 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7760 - val_loss: 0.5130 - val_accuracy: 0.7552\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7760 - val_loss: 0.5130 - val_accuracy: 0.7604\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7760 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7760 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7778 - val_loss: 0.5131 - val_accuracy: 0.7552\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4540 - accuracy: 0.7778 - val_loss: 0.5131 - val_accuracy: 0.7500\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.7778 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7778 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7778 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.7795 - val_loss: 0.5133 - val_accuracy: 0.7500\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7778 - val_loss: 0.5133 - val_accuracy: 0.7500\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7778 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7778 - val_loss: 0.5134 - val_accuracy: 0.7500\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.7795 - val_loss: 0.5135 - val_accuracy: 0.7500\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7795 - val_loss: 0.5136 - val_accuracy: 0.7500\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7795 - val_loss: 0.5136 - val_accuracy: 0.7500\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7795 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.7795 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4527 - accuracy: 0.7795 - val_loss: 0.5138 - val_accuracy: 0.7500\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7795 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.7778 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7795 - val_loss: 0.5139 - val_accuracy: 0.7500\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7778 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.7795 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7778 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7778 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7795 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7778 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7795 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7795 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7795 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7795 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7795 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7812 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7812 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7812 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7812 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7812 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7830 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7812 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7830 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7812 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7812 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7812 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7812 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7812 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7812 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7812 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7830 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7830 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7830 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7830 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7830 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7812 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7830 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7830 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7830 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7812 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7812 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7812 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7812 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7830 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7830 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7830 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7830 - val_loss: 0.5185 - val_accuracy: 0.7448\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7847 - val_loss: 0.5187 - val_accuracy: 0.7448\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7847 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7865 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7847 - val_loss: 0.5191 - val_accuracy: 0.7448\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.7448\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.5193 - val_accuracy: 0.7448\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7847 - val_loss: 0.5195 - val_accuracy: 0.7448\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7847 - val_loss: 0.5197 - val_accuracy: 0.7448\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7847 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7847 - val_loss: 0.5199 - val_accuracy: 0.7448\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.5200 - val_accuracy: 0.7448\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7847 - val_loss: 0.5201 - val_accuracy: 0.7448\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7847 - val_loss: 0.5202 - val_accuracy: 0.7448\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7847 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7865 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7865 - val_loss: 0.5205 - val_accuracy: 0.7344\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7847 - val_loss: 0.5206 - val_accuracy: 0.7344\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7830 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7847 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7847 - val_loss: 0.5209 - val_accuracy: 0.7344\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7847 - val_loss: 0.5210 - val_accuracy: 0.7344\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7847 - val_loss: 0.5211 - val_accuracy: 0.7344\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7847 - val_loss: 0.5212 - val_accuracy: 0.7344\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.5213 - val_accuracy: 0.7344\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7882 - val_loss: 0.5214 - val_accuracy: 0.7344\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7882 - val_loss: 0.5215 - val_accuracy: 0.7344\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.5215 - val_accuracy: 0.7344\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7882 - val_loss: 0.5216 - val_accuracy: 0.7344\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7882 - val_loss: 0.5217 - val_accuracy: 0.7344\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7882 - val_loss: 0.5218 - val_accuracy: 0.7344\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.5219 - val_accuracy: 0.7344\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.5219 - val_accuracy: 0.7292\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7882 - val_loss: 0.5220 - val_accuracy: 0.7344\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.5221 - val_accuracy: 0.7344\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5222 - val_accuracy: 0.7344\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.5222 - val_accuracy: 0.7344\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7882 - val_loss: 0.5223 - val_accuracy: 0.7344\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7865 - val_loss: 0.5225 - val_accuracy: 0.7396\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7882 - val_loss: 0.5225 - val_accuracy: 0.7396\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7882 - val_loss: 0.5226 - val_accuracy: 0.7396\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7865 - val_loss: 0.5227 - val_accuracy: 0.7396\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7882 - val_loss: 0.5227 - val_accuracy: 0.7396\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7865 - val_loss: 0.5228 - val_accuracy: 0.7396\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7865 - val_loss: 0.5228 - val_accuracy: 0.7396\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7865 - val_loss: 0.5229 - val_accuracy: 0.7396\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7882 - val_loss: 0.5229 - val_accuracy: 0.7396\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7865 - val_loss: 0.5230 - val_accuracy: 0.7396\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7865 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7847 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7865 - val_loss: 0.5232 - val_accuracy: 0.7396\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7865 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7847 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7865 - val_loss: 0.5234 - val_accuracy: 0.7344\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7865 - val_loss: 0.5235 - val_accuracy: 0.7344\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7865 - val_loss: 0.5236 - val_accuracy: 0.7344\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7865 - val_loss: 0.5236 - val_accuracy: 0.7344\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7865 - val_loss: 0.5237 - val_accuracy: 0.7292\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7865 - val_loss: 0.5238 - val_accuracy: 0.7292\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7865 - val_loss: 0.5238 - val_accuracy: 0.7292\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7865 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7865 - val_loss: 0.5240 - val_accuracy: 0.7292\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7847 - val_loss: 0.5240 - val_accuracy: 0.7292\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7865 - val_loss: 0.5241 - val_accuracy: 0.7292\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.5242 - val_accuracy: 0.7292\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.5242 - val_accuracy: 0.7292\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.5243 - val_accuracy: 0.7292\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.5244 - val_accuracy: 0.7292\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7865 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7865 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5246 - val_accuracy: 0.7292\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.5247 - val_accuracy: 0.7292\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7847 - val_loss: 0.5248 - val_accuracy: 0.7240\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7847 - val_loss: 0.5248 - val_accuracy: 0.7292\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7847 - val_loss: 0.5249 - val_accuracy: 0.7292\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7847 - val_loss: 0.5249 - val_accuracy: 0.7292\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7847 - val_loss: 0.5250 - val_accuracy: 0.7292\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7847 - val_loss: 0.5251 - val_accuracy: 0.7292\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7847 - val_loss: 0.5251 - val_accuracy: 0.7292\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7847 - val_loss: 0.5252 - val_accuracy: 0.7292\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7847 - val_loss: 0.5253 - val_accuracy: 0.7292\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7847 - val_loss: 0.5254 - val_accuracy: 0.7292\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7865 - val_loss: 0.5255 - val_accuracy: 0.7240\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7865 - val_loss: 0.5256 - val_accuracy: 0.7240\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7847 - val_loss: 0.5257 - val_accuracy: 0.7240\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7865 - val_loss: 0.5258 - val_accuracy: 0.7240\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7847 - val_loss: 0.5258 - val_accuracy: 0.7292\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7847 - val_loss: 0.5259 - val_accuracy: 0.7240\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7847 - val_loss: 0.5260 - val_accuracy: 0.7240\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7847 - val_loss: 0.5261 - val_accuracy: 0.7240\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7847 - val_loss: 0.5261 - val_accuracy: 0.7240\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7865 - val_loss: 0.5262 - val_accuracy: 0.7240\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7847 - val_loss: 0.5263 - val_accuracy: 0.7240\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7847 - val_loss: 0.5264 - val_accuracy: 0.7240\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7847 - val_loss: 0.5264 - val_accuracy: 0.7240\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7847 - val_loss: 0.5265 - val_accuracy: 0.7240\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7847 - val_loss: 0.5266 - val_accuracy: 0.7240\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7847 - val_loss: 0.5267 - val_accuracy: 0.7240\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5267 - val_accuracy: 0.7240\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5268 - val_accuracy: 0.7240\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7847 - val_loss: 0.5268 - val_accuracy: 0.7240\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7865 - val_loss: 0.5269 - val_accuracy: 0.7240\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7865 - val_loss: 0.5269 - val_accuracy: 0.7240\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7865 - val_loss: 0.5270 - val_accuracy: 0.7240\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7865 - val_loss: 0.5271 - val_accuracy: 0.7240\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7865 - val_loss: 0.5271 - val_accuracy: 0.7240\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7847 - val_loss: 0.5272 - val_accuracy: 0.7240\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7865 - val_loss: 0.5273 - val_accuracy: 0.7240\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7865 - val_loss: 0.5274 - val_accuracy: 0.7240\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.5274 - val_accuracy: 0.7240\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7865 - val_loss: 0.5275 - val_accuracy: 0.7240\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7830 - val_loss: 0.5275 - val_accuracy: 0.7240\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7830 - val_loss: 0.5276 - val_accuracy: 0.7240\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.5277 - val_accuracy: 0.7240\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5278 - val_accuracy: 0.7240\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5278 - val_accuracy: 0.7240\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7865 - val_loss: 0.5279 - val_accuracy: 0.7240\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.5280 - val_accuracy: 0.7240\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.5280 - val_accuracy: 0.7240\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.5281 - val_accuracy: 0.7240\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.5281 - val_accuracy: 0.7240\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7865 - val_loss: 0.5282 - val_accuracy: 0.7240\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7865 - val_loss: 0.5283 - val_accuracy: 0.7240\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5283 - val_accuracy: 0.7240\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5284 - val_accuracy: 0.7240\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5284 - val_accuracy: 0.7240\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7865 - val_loss: 0.5285 - val_accuracy: 0.7240\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7865 - val_loss: 0.5285 - val_accuracy: 0.7240\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4362 - accuracy: 0.7865 - val_loss: 0.5286 - val_accuracy: 0.7240\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.7865 - val_loss: 0.5287 - val_accuracy: 0.7240\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7865 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7865 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7240\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7240\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.5290 - val_accuracy: 0.7240\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.5291 - val_accuracy: 0.7240\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7865 - val_loss: 0.5291 - val_accuracy: 0.7240\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7865 - val_loss: 0.5292 - val_accuracy: 0.7240\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7240\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7240\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.5293 - val_accuracy: 0.7240\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7240\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7240\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7865 - val_loss: 0.5295 - val_accuracy: 0.7292\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7865 - val_loss: 0.5296 - val_accuracy: 0.7292\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7865 - val_loss: 0.5296 - val_accuracy: 0.7292\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7865 - val_loss: 0.5296 - val_accuracy: 0.7292\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7865 - val_loss: 0.5297 - val_accuracy: 0.7292\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7865 - val_loss: 0.5298 - val_accuracy: 0.7292\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7865 - val_loss: 0.5298 - val_accuracy: 0.7292\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7865 - val_loss: 0.5299 - val_accuracy: 0.7240\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7865 - val_loss: 0.5299 - val_accuracy: 0.7240\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7865 - val_loss: 0.5299 - val_accuracy: 0.7292\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7865 - val_loss: 0.5300 - val_accuracy: 0.7292\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7865 - val_loss: 0.5300 - val_accuracy: 0.7292\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7865 - val_loss: 0.5301 - val_accuracy: 0.7292\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7865 - val_loss: 0.5301 - val_accuracy: 0.7292\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7865 - val_loss: 0.5301 - val_accuracy: 0.7292\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7865 - val_loss: 0.5302 - val_accuracy: 0.7292\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7865 - val_loss: 0.5302 - val_accuracy: 0.7292\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7865 - val_loss: 0.5302 - val_accuracy: 0.7292\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7865 - val_loss: 0.5303 - val_accuracy: 0.7292\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7865 - val_loss: 0.5303 - val_accuracy: 0.7292\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7865 - val_loss: 0.5304 - val_accuracy: 0.7292\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7865 - val_loss: 0.5304 - val_accuracy: 0.7292\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7865 - val_loss: 0.5305 - val_accuracy: 0.7292\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7865 - val_loss: 0.5305 - val_accuracy: 0.7292\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.5305 - val_accuracy: 0.7292\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.5306 - val_accuracy: 0.7292\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.5306 - val_accuracy: 0.7292\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7865 - val_loss: 0.5307 - val_accuracy: 0.7292\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7865 - val_loss: 0.5307 - val_accuracy: 0.7292\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5308 - val_accuracy: 0.7292\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5308 - val_accuracy: 0.7292\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7865 - val_loss: 0.5309 - val_accuracy: 0.7292\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.5309 - val_accuracy: 0.7292\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.5310 - val_accuracy: 0.7292\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7882 - val_loss: 0.5310 - val_accuracy: 0.7292\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5311 - val_accuracy: 0.7292\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7865 - val_loss: 0.5312 - val_accuracy: 0.7292\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.5312 - val_accuracy: 0.7292\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7882 - val_loss: 0.5312 - val_accuracy: 0.7292\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5313 - val_accuracy: 0.7344\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5313 - val_accuracy: 0.7344\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5314 - val_accuracy: 0.7344\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5314 - val_accuracy: 0.7344\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.5316 - val_accuracy: 0.7344\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.5316 - val_accuracy: 0.7344\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5317 - val_accuracy: 0.7344\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5317 - val_accuracy: 0.7344\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5318 - val_accuracy: 0.7344\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.5318 - val_accuracy: 0.7344\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.5318 - val_accuracy: 0.7344\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.5319 - val_accuracy: 0.7344\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.5319 - val_accuracy: 0.7344\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.5320 - val_accuracy: 0.7344\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.5320 - val_accuracy: 0.7344\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5320 - val_accuracy: 0.7344\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.5321 - val_accuracy: 0.7344\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.5322 - val_accuracy: 0.7344\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.5322 - val_accuracy: 0.7344\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.5322 - val_accuracy: 0.7344\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7882 - val_loss: 0.5322 - val_accuracy: 0.7344\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7882 - val_loss: 0.5323 - val_accuracy: 0.7344\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7899 - val_loss: 0.5323 - val_accuracy: 0.7344\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.5324 - val_accuracy: 0.7344\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7899 - val_loss: 0.5324 - val_accuracy: 0.7344\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7882 - val_loss: 0.5324 - val_accuracy: 0.7396\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7899 - val_loss: 0.5325 - val_accuracy: 0.7344\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7899 - val_loss: 0.5325 - val_accuracy: 0.7344\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7882 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7899 - val_loss: 0.5326 - val_accuracy: 0.7396\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7899 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7899 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7899 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7899 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7899 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7899 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7899 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7882 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7899 - val_loss: 0.5330 - val_accuracy: 0.7396\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7917 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7899 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7899 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7899 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7917 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7899 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7917 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7899 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7917 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7899 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7917 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7917 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7917 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7917 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7917 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7917 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.7917 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.7917 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7899 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7917 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7917 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7899 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7917 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7899 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7917 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7917 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7917 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7917 - val_loss: 0.5340 - val_accuracy: 0.7448\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7917 - val_loss: 0.5341 - val_accuracy: 0.7448\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4311 - accuracy: 0.7917 - val_loss: 0.5342 - val_accuracy: 0.7448\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7917 - val_loss: 0.5342 - val_accuracy: 0.7448\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7899 - val_loss: 0.5342 - val_accuracy: 0.7448\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7917 - val_loss: 0.5343 - val_accuracy: 0.7448\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7917 - val_loss: 0.5343 - val_accuracy: 0.7448\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7917 - val_loss: 0.5343 - val_accuracy: 0.7448\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7917 - val_loss: 0.5344 - val_accuracy: 0.7448\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7917 - val_loss: 0.5344 - val_accuracy: 0.7448\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7917 - val_loss: 0.5344 - val_accuracy: 0.7448\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7917 - val_loss: 0.5345 - val_accuracy: 0.7448\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7917 - val_loss: 0.5345 - val_accuracy: 0.7448\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7917 - val_loss: 0.5346 - val_accuracy: 0.7448\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7917 - val_loss: 0.5346 - val_accuracy: 0.7448\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7899 - val_loss: 0.5346 - val_accuracy: 0.7448\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7917 - val_loss: 0.5347 - val_accuracy: 0.7448\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7917 - val_loss: 0.5347 - val_accuracy: 0.7448\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.5348 - val_accuracy: 0.7448\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7917 - val_loss: 0.5348 - val_accuracy: 0.7448\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7917 - val_loss: 0.5348 - val_accuracy: 0.7448\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7917 - val_loss: 0.5349 - val_accuracy: 0.7448\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7917 - val_loss: 0.5349 - val_accuracy: 0.7448\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7934 - val_loss: 0.5349 - val_accuracy: 0.7448\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7917 - val_loss: 0.5349 - val_accuracy: 0.7448\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7934 - val_loss: 0.5350 - val_accuracy: 0.7448\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7934 - val_loss: 0.5351 - val_accuracy: 0.7448\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7934 - val_loss: 0.5351 - val_accuracy: 0.7448\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7934 - val_loss: 0.5351 - val_accuracy: 0.7448\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7934 - val_loss: 0.5352 - val_accuracy: 0.7448\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7934 - val_loss: 0.5352 - val_accuracy: 0.7448\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7934 - val_loss: 0.5352 - val_accuracy: 0.7448\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7934 - val_loss: 0.5353 - val_accuracy: 0.7448\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7934 - val_loss: 0.5353 - val_accuracy: 0.7448\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7934 - val_loss: 0.5354 - val_accuracy: 0.7448\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7934 - val_loss: 0.5354 - val_accuracy: 0.7448\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7934 - val_loss: 0.5354 - val_accuracy: 0.7448\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7934 - val_loss: 0.5354 - val_accuracy: 0.7448\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7934 - val_loss: 0.5354 - val_accuracy: 0.7448\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7934 - val_loss: 0.5354 - val_accuracy: 0.7448\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7934 - val_loss: 0.5355 - val_accuracy: 0.7448\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7934 - val_loss: 0.5355 - val_accuracy: 0.7448\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7934 - val_loss: 0.5355 - val_accuracy: 0.7448\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7934 - val_loss: 0.5355 - val_accuracy: 0.7448\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7934 - val_loss: 0.5356 - val_accuracy: 0.7448\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7917 - val_loss: 0.5356 - val_accuracy: 0.7448\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7934 - val_loss: 0.5356 - val_accuracy: 0.7448\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7934 - val_loss: 0.5356 - val_accuracy: 0.7448\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7934 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7934 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7934 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7934 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7934 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7934 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7934 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7917 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7934 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7899 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7934 - val_loss: 0.5358 - val_accuracy: 0.7448\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7917 - val_loss: 0.5358 - val_accuracy: 0.7448\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7917 - val_loss: 0.5358 - val_accuracy: 0.7448\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7899 - val_loss: 0.5358 - val_accuracy: 0.7396\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7934 - val_loss: 0.5358 - val_accuracy: 0.7396\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7899 - val_loss: 0.5358 - val_accuracy: 0.7396\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7917 - val_loss: 0.5359 - val_accuracy: 0.7396\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7899 - val_loss: 0.5359 - val_accuracy: 0.7396\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7917 - val_loss: 0.5359 - val_accuracy: 0.7396\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7899 - val_loss: 0.5360 - val_accuracy: 0.7396\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7934 - val_loss: 0.5360 - val_accuracy: 0.7396\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7917 - val_loss: 0.5360 - val_accuracy: 0.7396\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7934 - val_loss: 0.5360 - val_accuracy: 0.7396\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7917 - val_loss: 0.5360 - val_accuracy: 0.7396\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7899 - val_loss: 0.5361 - val_accuracy: 0.7396\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7899 - val_loss: 0.5361 - val_accuracy: 0.7396\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.7899 - val_loss: 0.5361 - val_accuracy: 0.7396\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7917 - val_loss: 0.5361 - val_accuracy: 0.7396\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7899 - val_loss: 0.5361 - val_accuracy: 0.7396\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7899 - val_loss: 0.5361 - val_accuracy: 0.7396\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7882 - val_loss: 0.5361 - val_accuracy: 0.7396\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.5362 - val_accuracy: 0.7396\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.5362 - val_accuracy: 0.7396\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.7899 - val_loss: 0.5362 - val_accuracy: 0.7396\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7882 - val_loss: 0.5362 - val_accuracy: 0.7396\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.5363 - val_accuracy: 0.7396\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7917 - val_loss: 0.5363 - val_accuracy: 0.7396\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.5363 - val_accuracy: 0.7396\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7899 - val_loss: 0.5363 - val_accuracy: 0.7396\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.5364 - val_accuracy: 0.7396\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7899 - val_loss: 0.5364 - val_accuracy: 0.7396\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.5364 - val_accuracy: 0.7396\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5364 - val_accuracy: 0.7396\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5364 - val_accuracy: 0.7396\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7899 - val_loss: 0.5364 - val_accuracy: 0.7396\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5365 - val_accuracy: 0.7396\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7899 - val_loss: 0.5365 - val_accuracy: 0.7396\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.5365 - val_accuracy: 0.7396\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5365 - val_accuracy: 0.7396\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7917 - val_loss: 0.5365 - val_accuracy: 0.7396\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7917 - val_loss: 0.5366 - val_accuracy: 0.7396\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5366 - val_accuracy: 0.7396\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5366 - val_accuracy: 0.7396\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7917 - val_loss: 0.5367 - val_accuracy: 0.7396\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5367 - val_accuracy: 0.7396\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5368 - val_accuracy: 0.7396\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7917 - val_loss: 0.5368 - val_accuracy: 0.7396\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5368 - val_accuracy: 0.7396\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.5368 - val_accuracy: 0.7396\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5368 - val_accuracy: 0.7396\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7917 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7917 - val_loss: 0.5369 - val_accuracy: 0.7396\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7934 - val_loss: 0.5370 - val_accuracy: 0.7396\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.5370 - val_accuracy: 0.7396\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7917 - val_loss: 0.5370 - val_accuracy: 0.7396\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7882 - val_loss: 0.5370 - val_accuracy: 0.7396\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5370 - val_accuracy: 0.7396\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5371 - val_accuracy: 0.7396\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5371 - val_accuracy: 0.7396\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.5371 - val_accuracy: 0.7396\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7917 - val_loss: 0.5371 - val_accuracy: 0.7396\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7934 - val_loss: 0.5371 - val_accuracy: 0.7396\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7917 - val_loss: 0.5371 - val_accuracy: 0.7396\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7917 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7934 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7934 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7917 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7934 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7934 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.5373 - val_accuracy: 0.7396\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7934 - val_loss: 0.5373 - val_accuracy: 0.7396\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7969 - val_loss: 0.5374 - val_accuracy: 0.7396\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.5374 - val_accuracy: 0.7396\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.5374 - val_accuracy: 0.7396\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7917 - val_loss: 0.5374 - val_accuracy: 0.7396\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7934 - val_loss: 0.5374 - val_accuracy: 0.7396\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.5375 - val_accuracy: 0.7396\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7917 - val_loss: 0.5375 - val_accuracy: 0.7396\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7934 - val_loss: 0.5375 - val_accuracy: 0.7396\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7934 - val_loss: 0.5376 - val_accuracy: 0.7396\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7917 - val_loss: 0.5376 - val_accuracy: 0.7396\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7917 - val_loss: 0.5376 - val_accuracy: 0.7396\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7917 - val_loss: 0.5376 - val_accuracy: 0.7396\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7917 - val_loss: 0.5377 - val_accuracy: 0.7396\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7917 - val_loss: 0.5377 - val_accuracy: 0.7396\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7917 - val_loss: 0.5377 - val_accuracy: 0.7396\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7917 - val_loss: 0.5378 - val_accuracy: 0.7396\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7917 - val_loss: 0.5378 - val_accuracy: 0.7396\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7917 - val_loss: 0.5379 - val_accuracy: 0.7396\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7917 - val_loss: 0.5379 - val_accuracy: 0.7396\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7917 - val_loss: 0.5379 - val_accuracy: 0.7396\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7917 - val_loss: 0.5379 - val_accuracy: 0.7396\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7934 - val_loss: 0.5380 - val_accuracy: 0.7396\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7917 - val_loss: 0.5380 - val_accuracy: 0.7396\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7917 - val_loss: 0.5381 - val_accuracy: 0.7396\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7917 - val_loss: 0.5381 - val_accuracy: 0.7396\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7917 - val_loss: 0.5381 - val_accuracy: 0.7396\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7917 - val_loss: 0.5381 - val_accuracy: 0.7396\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7917 - val_loss: 0.5381 - val_accuracy: 0.7396\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7917 - val_loss: 0.5382 - val_accuracy: 0.7396\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7917 - val_loss: 0.5382 - val_accuracy: 0.7396\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7917 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7917 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7934 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7899 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7917 - val_loss: 0.5383 - val_accuracy: 0.7396\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7899 - val_loss: 0.5384 - val_accuracy: 0.7396\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7917 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7917 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7899 - val_loss: 0.5385 - val_accuracy: 0.7396\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7917 - val_loss: 0.5385 - val_accuracy: 0.7448\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7899 - val_loss: 0.5385 - val_accuracy: 0.7448\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5385 - val_accuracy: 0.7448\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5386 - val_accuracy: 0.7448\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.5386 - val_accuracy: 0.7448\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7899 - val_loss: 0.5387 - val_accuracy: 0.7448\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7899 - val_loss: 0.5387 - val_accuracy: 0.7448\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5387 - val_accuracy: 0.7448\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7917 - val_loss: 0.5387 - val_accuracy: 0.7448\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5388 - val_accuracy: 0.7448\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5388 - val_accuracy: 0.7448\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7899 - val_loss: 0.5389 - val_accuracy: 0.7448\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5389 - val_accuracy: 0.7448\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.7899 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7899 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7917 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.7917 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7917 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7917 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7917 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.7934 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7917 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7917 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7934 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7934 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7934 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7934 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7934 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7934 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7934 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.7934 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7934 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7934 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7934 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7934 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7934 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7934 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7934 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7934 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7917 - val_loss: 0.5396 - val_accuracy: 0.7500\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7917 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7934 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7917 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7917 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7917 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7917 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7917 - val_loss: 0.5400 - val_accuracy: 0.7500\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7917 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.7917 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7917 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7917 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7917 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.7917 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7917 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.7917 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7917 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7917 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7917 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.7917 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7917 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7917 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7917 - val_loss: 0.5409 - val_accuracy: 0.7448\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.7917 - val_loss: 0.5409 - val_accuracy: 0.7448\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7934 - val_loss: 0.5409 - val_accuracy: 0.7448\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7934 - val_loss: 0.5410 - val_accuracy: 0.7448\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7899 - val_loss: 0.5410 - val_accuracy: 0.7448\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7917 - val_loss: 0.5410 - val_accuracy: 0.7448\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7917 - val_loss: 0.5411 - val_accuracy: 0.7448\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7917 - val_loss: 0.5411 - val_accuracy: 0.7448\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7934 - val_loss: 0.5411 - val_accuracy: 0.7448\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7934 - val_loss: 0.5411 - val_accuracy: 0.7448\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7917 - val_loss: 0.5412 - val_accuracy: 0.7448\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7917 - val_loss: 0.5412 - val_accuracy: 0.7448\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7934 - val_loss: 0.5413 - val_accuracy: 0.7448\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.7934 - val_loss: 0.5413 - val_accuracy: 0.7448\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.5414 - val_accuracy: 0.7448\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.5414 - val_accuracy: 0.7448\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.5414 - val_accuracy: 0.7448\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.5414 - val_accuracy: 0.7448\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.7917 - val_loss: 0.5415 - val_accuracy: 0.7448\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7934 - val_loss: 0.5415 - val_accuracy: 0.7448\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7934 - val_loss: 0.5415 - val_accuracy: 0.7448\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7917 - val_loss: 0.5416 - val_accuracy: 0.7448\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7917 - val_loss: 0.5416 - val_accuracy: 0.7448\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7934 - val_loss: 0.5417 - val_accuracy: 0.7448\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7934 - val_loss: 0.5417 - val_accuracy: 0.7448\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.7917 - val_loss: 0.5417 - val_accuracy: 0.7448\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7917 - val_loss: 0.5418 - val_accuracy: 0.7448\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7917 - val_loss: 0.5418 - val_accuracy: 0.7448\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7934 - val_loss: 0.5418 - val_accuracy: 0.7448\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.7934 - val_loss: 0.5418 - val_accuracy: 0.7448\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7899 - val_loss: 0.5419 - val_accuracy: 0.7448\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7899 - val_loss: 0.5419 - val_accuracy: 0.7448\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7917 - val_loss: 0.5420 - val_accuracy: 0.7448\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7917 - val_loss: 0.5420 - val_accuracy: 0.7448\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7934 - val_loss: 0.5420 - val_accuracy: 0.7448\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.7899 - val_loss: 0.5420 - val_accuracy: 0.7448\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7934 - val_loss: 0.5420 - val_accuracy: 0.7448\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7899 - val_loss: 0.5421 - val_accuracy: 0.7448\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.7917 - val_loss: 0.5421 - val_accuracy: 0.7448\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7917 - val_loss: 0.5422 - val_accuracy: 0.7448\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7934 - val_loss: 0.5422 - val_accuracy: 0.7448\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7917 - val_loss: 0.5422 - val_accuracy: 0.7448\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7917 - val_loss: 0.5423 - val_accuracy: 0.7448\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7917 - val_loss: 0.5422 - val_accuracy: 0.7448\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7917 - val_loss: 0.5423 - val_accuracy: 0.7448\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7934 - val_loss: 0.5423 - val_accuracy: 0.7448\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7917 - val_loss: 0.5424 - val_accuracy: 0.7448\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7934 - val_loss: 0.5424 - val_accuracy: 0.7448\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7934 - val_loss: 0.5424 - val_accuracy: 0.7448\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7934 - val_loss: 0.5425 - val_accuracy: 0.7448\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7934 - val_loss: 0.5425 - val_accuracy: 0.7448\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7934 - val_loss: 0.5425 - val_accuracy: 0.7448\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.7934 - val_loss: 0.5425 - val_accuracy: 0.7448\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7917 - val_loss: 0.5425 - val_accuracy: 0.7448\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7917 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7934 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7934 - val_loss: 0.5426 - val_accuracy: 0.7500\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7934 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7934 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.7917 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7934 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.7934 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.7934 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7934 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7934 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7934 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7934 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.5430 - val_accuracy: 0.7552\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7934 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7934 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7934 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7934 - val_loss: 0.5431 - val_accuracy: 0.7552\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5432 - val_accuracy: 0.7500\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.7934 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7934 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7934 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7934 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7934 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7934 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7934 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5435 - val_accuracy: 0.7500\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7934 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.7934 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.7934 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7934 - val_loss: 0.5439 - val_accuracy: 0.7500\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5440 - val_accuracy: 0.7500\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5440 - val_accuracy: 0.7500\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7934 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5440 - val_accuracy: 0.7552\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5441 - val_accuracy: 0.7552\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5441 - val_accuracy: 0.7552\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5441 - val_accuracy: 0.7552\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7934 - val_loss: 0.5441 - val_accuracy: 0.7552\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5441 - val_accuracy: 0.7552\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.7934 - val_loss: 0.5441 - val_accuracy: 0.7552\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5443 - val_accuracy: 0.7552\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5443 - val_accuracy: 0.7552\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7934 - val_loss: 0.5443 - val_accuracy: 0.7552\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.7934 - val_loss: 0.5443 - val_accuracy: 0.7552\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5443 - val_accuracy: 0.7552\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7934 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5445 - val_accuracy: 0.7552\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5446 - val_accuracy: 0.7552\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5447 - val_accuracy: 0.7552\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5447 - val_accuracy: 0.7552\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.5447 - val_accuracy: 0.7552\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.5447 - val_accuracy: 0.7552\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5447 - val_accuracy: 0.7552\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7951 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5448 - val_accuracy: 0.7552\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5449 - val_accuracy: 0.7552\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5449 - val_accuracy: 0.7552\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5449 - val_accuracy: 0.7552\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5449 - val_accuracy: 0.7552\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.5449 - val_accuracy: 0.7552\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.7951 - val_loss: 0.5449 - val_accuracy: 0.7552\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.5450 - val_accuracy: 0.7552\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.5450 - val_accuracy: 0.7552\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.5450 - val_accuracy: 0.7552\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.7951 - val_loss: 0.5450 - val_accuracy: 0.7552\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5450 - val_accuracy: 0.7552\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5450 - val_accuracy: 0.7552\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5450 - val_accuracy: 0.7552\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5451 - val_accuracy: 0.7552\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.5451 - val_accuracy: 0.7552\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5451 - val_accuracy: 0.7552\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.5451 - val_accuracy: 0.7552\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.7951 - val_loss: 0.5451 - val_accuracy: 0.7552\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.5451 - val_accuracy: 0.7552\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.5451 - val_accuracy: 0.7552\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.5452 - val_accuracy: 0.7552\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5452 - val_accuracy: 0.7552\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.7951 - val_loss: 0.5452 - val_accuracy: 0.7552\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5452 - val_accuracy: 0.7552\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.7951 - val_loss: 0.5452 - val_accuracy: 0.7552\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.7951 - val_loss: 0.5452 - val_accuracy: 0.7552\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5452 - val_accuracy: 0.7552\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.7934 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.7934 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.7934 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7917 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7934 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7934 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.7934 - val_loss: 0.5454 - val_accuracy: 0.7552\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7934 - val_loss: 0.5453 - val_accuracy: 0.7552\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7934 - val_loss: 0.5454 - val_accuracy: 0.7552\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5454 - val_accuracy: 0.7552\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7951 - val_loss: 0.5454 - val_accuracy: 0.7552\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.7951 - val_loss: 0.5454 - val_accuracy: 0.7552\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7934 - val_loss: 0.5454 - val_accuracy: 0.7552\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7934 - val_loss: 0.5454 - val_accuracy: 0.7552\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.7951 - val_loss: 0.5454 - val_accuracy: 0.7552\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7951 - val_loss: 0.5454 - val_accuracy: 0.7552\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7934 - val_loss: 0.5454 - val_accuracy: 0.7552\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7934 - val_loss: 0.5455 - val_accuracy: 0.7552\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7934 - val_loss: 0.5455 - val_accuracy: 0.7552\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.7934 - val_loss: 0.5455 - val_accuracy: 0.7552\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.7951 - val_loss: 0.5455 - val_accuracy: 0.7552\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.7951 - val_loss: 0.5455 - val_accuracy: 0.7552\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.7934 - val_loss: 0.5455 - val_accuracy: 0.7552\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.7951 - val_loss: 0.5455 - val_accuracy: 0.7552\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.7951 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.7986 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.7951 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.7934 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.7951 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.7934 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.7951 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.7951 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.7934 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.7934 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.7934 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.7951 - val_loss: 0.5456 - val_accuracy: 0.7552\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.7951 - val_loss: 0.5457 - val_accuracy: 0.7552\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.7951 - val_loss: 0.5457 - val_accuracy: 0.7552\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.7951 - val_loss: 0.5457 - val_accuracy: 0.7552\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.7951 - val_loss: 0.5457 - val_accuracy: 0.7552\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.7951 - val_loss: 0.5457 - val_accuracy: 0.7552\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5457 - val_accuracy: 0.7500\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.7951 - val_loss: 0.5457 - val_accuracy: 0.7500\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.7951 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.7951 - val_loss: 0.5457 - val_accuracy: 0.7500\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.7951 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.7951 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.7951 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7951 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7969 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7951 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7951 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7951 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7951 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.7951 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7951 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7951 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.7951 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7951 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.7969 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.7969 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.7951 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7951 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7951 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7951 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5461 - val_accuracy: 0.7500\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.7951 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.7951 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.7951 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.7951 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.7951 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.7951 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7951 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.7951 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.7951 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.7934 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.7951 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.7951 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5464 - val_accuracy: 0.7500\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.7969 - val_loss: 0.5464 - val_accuracy: 0.7500\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.7951 - val_loss: 0.5464 - val_accuracy: 0.7500\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.7951 - val_loss: 0.5464 - val_accuracy: 0.7500\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.7969 - val_loss: 0.5464 - val_accuracy: 0.7500\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.7951 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.7951 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.7951 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.7951 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7951 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7951 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.7951 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7951 - val_loss: 0.5465 - val_accuracy: 0.7500\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7951 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7951 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.7951 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7969 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7951 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.7951 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.7951 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.7951 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.7934 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.7934 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.7951 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.7934 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.7951 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.7951 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.7951 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.7934 - val_loss: 0.5469 - val_accuracy: 0.7500\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.7951 - val_loss: 0.5469 - val_accuracy: 0.7500\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.7934 - val_loss: 0.5469 - val_accuracy: 0.7500\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.7934 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.7934 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.7951 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.7934 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.7934 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.7951 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.7951 - val_loss: 0.5470 - val_accuracy: 0.7500\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.7934 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.7934 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.7951 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.7934 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.7951 - val_loss: 0.5471 - val_accuracy: 0.7500\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.7934 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.7934 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.7917 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.7951 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.7934 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.7951 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.7934 - val_loss: 0.5473 - val_accuracy: 0.7500\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.7934 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.7934 - val_loss: 0.5473 - val_accuracy: 0.7500\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.7934 - val_loss: 0.5473 - val_accuracy: 0.7500\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.7951 - val_loss: 0.5473 - val_accuracy: 0.7500\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.7951 - val_loss: 0.5473 - val_accuracy: 0.7500\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.7934 - val_loss: 0.5473 - val_accuracy: 0.7500\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.7951 - val_loss: 0.5473 - val_accuracy: 0.7500\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.7917 - val_loss: 0.5473 - val_accuracy: 0.7500\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.7934 - val_loss: 0.5474 - val_accuracy: 0.7500\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.7969 - val_loss: 0.5474 - val_accuracy: 0.7500\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.7951 - val_loss: 0.5474 - val_accuracy: 0.7500\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.7934 - val_loss: 0.5474 - val_accuracy: 0.7500\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.7934 - val_loss: 0.5474 - val_accuracy: 0.7500\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.7951 - val_loss: 0.5475 - val_accuracy: 0.7500\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.7917 - val_loss: 0.5475 - val_accuracy: 0.7500\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.7951 - val_loss: 0.5475 - val_accuracy: 0.7500\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.7917 - val_loss: 0.5475 - val_accuracy: 0.7500\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.7969 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.7969 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.7934 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.7934 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.7951 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.7934 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.7951 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.7934 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.7917 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.7917 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.7934 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.7934 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.7934 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.7951 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.7934 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.7917 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.7951 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.7934 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.7951 - val_loss: 0.5477 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6d52d3b340>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6gAAAHSCAYAAADhZ+amAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABKyklEQVR4nO3deXzddZ3v8dcnSZdhKaWlWqYsLXORoQgUjOABhGAdRUU2dQRhCsPMxMLgMs5QYBb1ylUocGcY57L1gjIMHXngQkFRULiGDhpHioDQYgGxQGUrhZaKQNvke//45bQn6UlyTnKSs+T1fDzySM5vyfmmP5a8+/l+P99IKSFJkiRJUrU1VXsAkiRJkiSBAVWSJEmSVCMMqJIkSZKkmmBAlSRJkiTVBAOqJEmSJKkmGFAlSZIkSTWhpdoDKGaXXXZJM2fOrPYwJEmSJEkVdv/997+UUppW7FxNBtSZM2eybNmyag9DkiRJklRhEfFUf+ec4itJkiRJqgkGVEmSJElSTTCgSpIkSZJqQk2uQZUkSZKkQps2bWL16tW88cYb1R6KSjRx4kR22203xo0bV/I9BlRJkiRJNW/16tXsuOOOzJw5k4io9nA0iJQSa9euZfXq1cyaNavk+5ziK0mSJKnmvfHGG0ydOtVwWicigqlTp5Zd8TagSpIkSaoLhtP6MpTnZUCVJEmSpEGsXbuWOXPmMGfOHKZPn86MGTO2vN64ceOA9y5btoxPf/rTZb3fzJkzeemll4Yz5LrkGlRJkiRJGsTUqVN58MEHAfjiF7/IDjvswN/93d9tOb9582ZaWorHq9bWVlpbW0djmHXPCqokSZKkxtTZCRddlH0eAWeccQaf+9znOProoznvvPP4+c9/zmGHHcZBBx3EYYcdxsqVKwHo6Ojg2GOPBbJwe+aZZ9LW1sZee+3FV7/61ZLf76mnnmLu3LkccMABzJ07l6effhqAb37zm7z97W/nwAMP5MgjjwRg+fLlHHLIIcyZM4cDDjiAxx9/vMI//ciwgipJkiSpvnz2s9BTzezX+vXwy19Cdzc0NcEBB8BOO/V//Zw5cPnlZQ/lscce46677qK5uZlXX32VpUuX0tLSwl133cXf//3f8+1vf3ube371q1/x4x//mA0bNrDPPvtw1llnlbQVyznnnMO8efM4/fTT+drXvsanP/1plixZwpe+9CXuvPNOZsyYwbp16wC4+uqr+cxnPsOpp57Kxo0b6erqKvtnqwYDqiRJkqTGs359Fk4h+7x+/cABdYg+9rGP0dzc3POW6zn99NN5/PHHiQg2bdpU9J4PfehDTJgwgQkTJvCWt7yFF154gd12223Q9+rs7OQ73/kOAH/2Z3/GggULADj88MM544wz+NM//VNOOukkAHK5HF/+8pdZvXo1J510EnvvvXclftwRZ0CVJEmSVF9KqXR2dsLcubBxI4wfD4sXQy5X8aFsv/32W77+p3/6J44++mhuueUWVq1aRVtbW9F7JkyYsOXr5uZmNm/ePKT3znfJvfrqq/nv//5vbr/9dubMmcODDz7IJz7xCQ499FBuv/123v/+93Pttdfynve8Z0jvM5pKWoMaEcdExMqIeCIizi9yfqeI+G5EPBQRyyPiz0u9V5IkSZIqLpeDu++GCy/MPo9AOO1r/fr1zJgxA4Drr7++4t//sMMO46abbgJg8eLFHHHEEQD8+te/5tBDD+VLX/oSu+yyC8888wxPPvkke+21F5/+9Kc57rjj+OUvf1nx8YyEQSuoEdEMXAH8CbAauC8ibksprSi47K+BFSmlD0fENGBlRCwGukq4V5IkSZIqL5cblWCat2DBAk4//XT++Z//uSLVygMOOICmpqym+Kd/+qd89atf5cwzz+TSSy9l2rRpfP3rXwfg3HPP5fHHHyelxNy5cznwwAO5+OKLufHGGxk3bhzTp0/n85///LDHMxoipTTwBRE54Isppff3vL4AIKV0UcE1FwC7kwXVmcCPgLcBhw52bzGtra1p2bJlQ/uJJEmSJDWcRx99lH333bfaw1CZij23iLg/pVR0351SpvjOAJ4peL2651ih/wPsCzwLPAx8JqXUXeK99eWee+Cf/mnEWlVLkiRJ0lhVSkCNIsf6ll3fDzwI/CEwB/g/ETGpxHuzN4loj4hlEbFszZo1JQyrCvILrf/X/8o+G1IlSZIkqWJKCairyabv5u1GVikt9OfAd1LmCeA3wB+XeC8AKaVFKaXWlFLrtGnTSh3/6Oro2NqqeuPG7LUkSZIkqSJKCaj3AXtHxKyIGA+cDNzW55qngbkAEfFWYB/gyRLvrR9tbdCzxxHjx2evJUmSJEkVMWhATSltBs4B7gQeBW5OKS2PiPkRMb/nsguBwyLiYeBu4LyU0kv93TsSP8ioyOXgk5/Mvr7ttlHtCCZJkiRJjW7QbWYAUkrfB77f59jVBV8/C7yv1Hvr2gEHZJ9nz67uOCRJkiSpwZQyxVeFdtwx+/zqq9UdhyRJkqRR09bWxp133tnr2OWXX87ZZ5894D357TM/+MEPsm7dum2u+eIXv8hll1024HsvWbKEFStWbHn9+c9/nrvuuquM0RfX0dHBscceO+zvU0kG1HLlA+qGDdUdhyRJkqRRc8opp3DTTTf1OnbTTTdxyimnlHT/97//fSZPnjyk9+4bUL/0pS/x3ve+d0jfq9YZUMtlQJUkSZLqQmcnXHRRZXaH/OhHP8r3vvc93nzzTQBWrVrFs88+yxFHHMFZZ51Fa2sr++23H1/4wheK3j9z5kxeeuklAL785S+zzz778N73vpeVK1duueb//t//yzvf+U4OPPBAPvKRj/D73/+en/70p9x2222ce+65zJkzh1//+tecccYZfOtb3wLg7rvv5qCDDmL//ffnzDPP3DK+mTNn8oUvfIGDDz6Y/fffn1/96lcl/6zf+MY32H///Xn729/OeeedB0BXVxdnnHEGb3/729l///35l3/5FwC++tWvMnv2bA444ABOPvnkMv9Ut1XSGlQVMKBKkiRJVfXZz8KDDw58zfr18MtfZrtENjVlrWR22qn/6+fMgcsv7//81KlTOeSQQ7jjjjs4/vjjuemmm/j4xz9ORPDlL3+ZKVOm0NXVxdy5c/nlL3/JAfneNX3cf//93HTTTTzwwANs3ryZgw8+mHe84x0AnHTSSfzVX/0VAP/4j//Iddddx6c+9SmOO+44jj32WD760Y/2+l5vvPEGZ5xxBnfffTdve9vbmDdvHldddRWf/exnAdhll134xS9+wZVXXslll13GtddeO/AfGvDss89y3nnncf/997Pzzjvzvve9jyVLlrD77rvz29/+lkceeQRgy3Tliy++mN/85jdMmDCh6BTmcllBLZcBVZIkSap569dn4RSyz+vXD/97Fk7zLZzee/PNN3PwwQdz0EEHsXz58l7Tcfv6r//6L0488US22247Jk2axHHHHbfl3COPPMK73/1u9t9/fxYvXszy5QNvgLJy5UpmzZrF2972NgBOP/10li5duuX8SSedBMA73vEOVq1aVdLPeN9999HW1sa0adNoaWnh1FNPZenSpey11148+eSTfOpTn+KOO+5g0qRJABxwwAGceuqp3HjjjbS0DL/+aQW1XPmA+s1vwh/9kVvNSJIkSaNsoEpnXmcnzJ0LGzfC+PGwePHwf3U/4YQT+NznPscvfvELXn/9dQ4++GB+85vfcNlll3Hfffex8847c8YZZ/DGG28M+H0ioujxM844gyVLlnDggQdy/fXX09HRMeD3SSkNeH7ChAkANDc3s3nz5gGvHex77rzzzjz00EPceeedXHHFFdx888187Wtf4/bbb2fp0qXcdtttXHjhhSxfvnxYQdUKarkefTT7/N3vZv/EV2JCuyRJkqSKyuXg7rvhwguzz5WoK+2www60tbVx5plnbqmevvrqq2y//fbstNNOvPDCC/zgBz8Y8HsceeSR3HLLLbz++uts2LCB7373u1vObdiwgV133ZVNmzaxePHiLcd33HFHNhSZwfnHf/zHrFq1iieeeAKA//iP/+Coo44a1s946KGHcs899/DSSy/R1dXFN77xDY466iheeukluru7+chHPsKFF17IL37xC7q7u3nmmWc4+uijueSSS1i3bh2/+93vhvX+VlDLlQ+kKWV/HdPRYRVVkiRJqkG5XOV/VT/llFM46aSTtkz1PfDAAznooIPYb7/92GuvvTj88MMHvP/ggw/m4x//OHPmzGHPPffk3e9+95ZzF154IYceeih77rkn+++//5ZQevLJJ/NXf/VXfPWrX93SHAlg4sSJfP3rX+djH/sYmzdv5p3vfCfz588v6+e5++672W233ba8/uY3v8lFF13E0UcfTUqJD37wgxx//PE89NBD/Pmf/zndPfOmL7roIrq6ujjttNNYv349KSX+5m/+ZsidivNisLJwNbS2tqb8fkE1p7MTDjsMImDixMr9dYwkSZKkfj366KPsu+++1R6GylTsuUXE/Sml1mLXO8W3XLkcTJsGBx9sOJUkSZKkCjKgDsUuu8CsWYZTSZIkSaogA+pQ7Lij28xIkiRJUoUZUIfCgCpJkiSNulrsn6P+DeV5GVCHwoAqSZIkjaqJEyeydu1aQ2qdSCmxdu1aJk6cWNZ9bjMzFJMmwauvVnsUkiRJ0pix2267sXr1atasWVPtoahEEydO7LWFTSkMqEPx2mvw4ovZljM2SpIkSZJG3Lhx45g1a1a1h6ER5hTfMnUuepiLbtmHztcPhLlzs5AqSZIkSRo2A2oZOjuh7ex9+YfuC5nL3XS+eTB0dFR7WJIkSZLUEAyoZejogE1dzSSa2Mg4OpqOhra2ag9LkiRJkhqCAbUMbW3Q3BJAYjybaPvHd7sGVZIkSZIqxIBahlwOPvlJgOA2jiP3/knVHpIkSZIkNQwDapnmzMk+v43HYN26ag5FkiRJkhqKAbVMkydnn9cx2YAqSZIkSRVkQC3Tzjtnnw2okiRJklRZBtQy9aqgLlniPqiSJEmSVCEG1DLlA+p/cBqdd74Kc+caUiVJkiSpAgyoZXr88ezzt/kIc7mLzjcPzjZIlSRJkiQNiwG1TPffn31ONLORcXQ0vSfbIFWSJEmSNCwt1R5AvXnPe7LPQTfjYzNtV3wMcvtXd1CSJEmS1ACsoJYpl4O3vAUO2vHX3D370+TaDaeSJEmSVAkG1CF461thj0mvkOu6t9pDkSRJkqSGYUAdgsmTYV33Tu6DKkmSJEkVZEAdgsmTYd0bE+Cll9xiRpIkSZIqxIA6BJtefIVVr0yic3Or+6BKkiRJUoUYUMvU2Ql33TeJdezMXO52H1RJkiRJqhADapk6OqArNQHRsw/q0e6DKkmSJEkVYEAtU1sbtLQEAOPYRNtn5mR7z0iSJEmShsWAWqZcDv7hH7Kvv86fkzuiuboDkiRJkqQGYUAdgne9K/u8O6th7drqDkaSJEmSGoQBdQh22SX7vJapBlRJkiRJqhAD6hBMnZp9fqnprXD77W4zI0mSJEkVYEAdgnxA/Wb3iXQu3eReqJIkSZJUASUF1Ig4JiJWRsQTEXF+kfPnRsSDPR+PRERXREzpObcqIh7uObes0j9ANTz8MEDiTo5hLne5F6okSZIkVcCgATUimoErgA8As4FTImJ24TUppUtTSnNSSnOAC4B7UkovF1xydM/51soNvXruuSf7nGjq2Qv1Pe6FKkmSJEnDVEoF9RDgiZTSkymljcBNwPEDXH8K8I1KDK5WtbVBRADdjGczbVd8zL1QJUmSJGmYSgmoM4BnCl6v7jm2jYjYDjgG+HbB4QT8MCLuj4j2oQ60luRyMGcO7LnDWu6e+qfk2vev9pAkSZIkqe61lHBNFDmW+rn2w8BP+kzvPTyl9GxEvAX4UUT8KqW0dJs3ycJrO8Aee+xRwrCq64/+CF5/KpHb8ENICaLYH5MkSZIkqVSlVFBXA7sXvN4NeLafa0+mz/TelNKzPZ9fBG4hmzK8jZTSopRSa0qpddq0aSUMq7qmToW1r/8BbNwIP/5xtYcjSZIkSXWvlIB6H7B3RMyKiPFkIfS2vhdFxE7AUcCtBce2j4gd818D7wMeqcTAq+2Np1/kpde35yfk4EMfcpsZSZIkSRqmQQNqSmkzcA5wJ/AocHNKaXlEzI+I+QWXngj8MKX0WsGxtwL3RsRDwM+B21NKd1Ru+NXR2Qn/eedUEk38CXfRufEdbjMjSZIkScNUyhpUUkrfB77f59jVfV5fD1zf59iTwIHDGmEN6uiArpRl+42MpyOOJuc2M5IkSZI0LKVM8VUfbW0wbnzWFKmFzbT92e5uMyNJkiRJw2RAHYJcDr7+9ezrC7iI3Oz11R2QJEmSJDWAkqb4alsf+ED2eceWN+DF31d3MJIkSZLUAKygDtFOO8H48bAkTqTztjV28ZUkSZKkYTKgDtHPfgabNib+a9MhzH3sSjrbLjCkSpIkSdIwGFCHqKMDEgBNbGQcHZsOd6sZSZIkSRoGA+oQtbVBcxNAYjybaBv3k+ygJEmSJGlIDKhDlMvB8ScEf9C8kbub3kfux19xqxlJkiRJGga7+A7DlCnwetcENtIEs2dXeziSJEmSVNesoA5RZyf8+79nXx/DnXT+27LqDkiSJEmS6pwBdYg6OqBrc9YmaRPj6Pif99jFV5IkSZKGwYA6RG1tMK65C4Bmumjr/n928ZUkSZKkYTCgDlEuBzd/+QkAPsvl5Frus4uvJEmSJA2DAXUYPvA3f0xEYrumN+CjH7WLryRJkiQNgwF1GMaNg512Cr7f/GE6f97sGlRJkiRJGgYD6jB0dsL69Ymfb5rD3F9fQ2fbBYZUSZIkSRoiA+owdHRASgBNbGQcHZsOt1GSJEmSJA2RAXUY2tqgpRkgMZ5NtI37iY2SJEmSJGmIDKjDkMvBh48LIFjIAnLf/XsbJUmSJEnSEBlQh6GzE26/Pft6AZfSed0K16BKkiRJ0hAZUIehowM2b86+3sg4Or75Isyda0iVJEmSpCEwoA5DWxuMH5993Uw3benHsHGjjZIkSZIkaQgMqMOQy8GPfgRN0c3JfINc/HeWWG2UJEmSJEllM6AO0xFHwFunN/HLpoPo3PdMuPtuGyVJkiRJ0hAYUIepsxNeeAEe6t6fuY/+G50P71DtIUmSJElSXTKgDlNHB3R3JyDYmFro+Otv2iRJkiRJkobAgDpMbW3Q0tQNJMazibbu/2eTJEmSJEkaAgPqMOVy8HenPgcEJ/FtaGmxSZIkSZIkDYEBtQLeevBuAHyDU5jLXXRikyRJkiRJKpcBtQKeeSb73E0LGzcFHTc8Vd0BSZIkSVIdMqBWwPHHAySCLsanN2n72uk2SpIkSZKkMhlQK+DII2GX7X7PW3iRy/kMua57bZQkSZIkSWVqqfYAGkFnJ7z8xnZ0sx2f5V/Zv/lxcjZKkiRJkqSyWEGtgI4OSCmAYCPj6PjgJVl7X0mSJElSyQyoFdDWBi3N3QCMYzNt31/gGlRJkiRJKpMBtQJyOfjKn/wYgGP4AWze7BpUSZIkSSqTAbVCds9le6HeyvHM7f4hnVOPrfKIJEmSJKm+GFAr5PHYB0gkmtnIeDoemFTtIUmSJElSXTGgVsjcuZC1SepmPBvdC1WSJEmSymRArZBcDvadtoYd2OBeqJIkSZI0BAbUCunshMde3oUNTOKz/CudzUdk7X0lSZIkSSUxoFZIRwd0dTeR7YU63r1QJUmSJKlMJQXUiDgmIlZGxBMRcX6R8+dGxIM9H49ERFdETCnl3kbR1gbjW7q3vJ76vetdgypJkiRJZRg0oEZEM3AF8AFgNnBKRMwuvCaldGlKaU5KaQ5wAXBPSunlUu5tFLkcXPy+uwDoponPbr6Mzhser/KoJEmSJKl+lFJBPQR4IqX0ZEppI3ATcPwA158CfGOI99a113fPbzXTxEbG0cFR1R6SJEmSJNWNUgLqDOCZgtere45tIyK2A44Bvl3uvY2gbd6eRAAkmqObtoNerfaQJEmSJKlulBJQo8ix1M+1HwZ+klJ6udx7I6I9IpZFxLI1a9aUMKza1NTzE0dK8KlPuQ5VkiRJkkpUSkBdDexe8Ho34Nl+rj2ZrdN7y7o3pbQopdSaUmqdNm1aCcOqPR0dkLoTEGymhY5Nh7sXqiRJkiSVqJSAeh+wd0TMiojxZCH0tr4XRcROwFHAreXe2yja2mDc+K2vpza97F6okiRJklSiQQNqSmkzcA5wJ/AocHNKaXlEzI+I+QWXngj8MKX02mD3VvIHqCW5HPzzp34DJLpo4rNd/5vOh3eo9rAkSZIkqS60lHJRSun7wPf7HLu6z+vrgetLubeRrX/4GWAvyHfy/fZacu3VHpUkSZIk1b5SpviqDG0fmUoTXUCimS7a5qyr9pAkSZIkqS4YUCtt//1pamoia2AccPnldvKVJEmSpBIYUCusowO6ezbS2UQLN2w82U6+kiRJklQCA2qFtbVBS0sCEokmvs4ZdE49ttrDkiRJkqSaZ0CtsFwOzvzQmp5XwWaa6XhgUlXHJEmSJEn1wIA6AuZN/yHNhY2SuKfaQ5IkSZKkmmdAHQkHHUSQ2NIoaZIVVEmSJEkajAF1BHSs3Z8UzQBsYhw3/O81dvKVJEmSpEEYUEdAWxs0N3WTNUoKvt71Z3Re8l/VHpYkSZIk1TQD6gjI5eDMD7/U8yrYyDhuuG2yVVRJkiRJGoABdYTMWzC9p1ES2XYz3fPovOHxKo9KkiRJkmqXAXWE5HJw0tGv9LwKNtFCB0dVdUySJEmSVMsMqCPove98FUhAoptmpk7aXO0hSZIkSVLNMqCOoLUPPgM9280E3Tzw3dXVHpIkSZIk1SwD6ghq+8hUWsiqpokmvv7ooXQuerjKo5IkSZKk2mRAHUG59v05ea/7el71rEP99tqqjkmSJEmSapUBdYS9O7eZXutQp0W1hyRJkiRJNcmAOsLWrsnC6ZZ1qI/vWO0hSZIkSVJNMqCOsG3Wof7iADo7qzwoSZIkSapBBtQRlmvfnz9r/RX5KuqmzdBxw1PVHpYkSZIk1RwD6ih412757WV61qE+v7yq45EkSZKkWmRAHQVr2YUoXIf68sxqD0mSJEmSao4BdRS0Tf8V49gE9KxDvXdv16FKkiRJUh8G1FGQm7c3ZzZdz5Z1qN3hOlRJkiRJ6sOAOhpyOQ46YvueF9k61HUrflvVIUmSJElSrTGgjpK1U95G0A0EAP9y76FO85UkSZKkAgbUUdI2/Vc000V+mu/mbujoqPKgJEmSJKmGGFBHSW7e3nyu6fItrxNNrFu+uv8bJEmSJGmMMaCOllyOya35ab6Zf/nGrk7zlSRJkqQeBtRR1NZGn2m+4TRfSZIkSephQB1FucmP8jn+ecvrRDjNV5IkSZJ6GFBHU1sbk5s2EHRtOXTZf/4hixZVcUySJEmSVCMMqKMpl6PtlD+kmW7y03y7U3DOObgWVZIkSdKYZ0AdZbn9XuUKzqFpS7OkYPNmt5yRJEmSJAPqaGtro338v/N3XEJWRU2klFi3rsrjkiRJkqQqM6COtlwOzjyTybwKdAMBwP++rNtpvpIkSZLGNANqNcybR1vzvb3WonZ1B5dcUu2BSZIkSVL1GFCrIZcj97eH8WG+2+vwbbfZLEmSJEnS2GVArZbJk1nApTTRxZaOvt3JKqokSZKkMcuAWi1tbeRalnEct/U6bBVVkiRJ0lhlQK2WXA4+97kiVVSsokqSJEkakwyo1TR5Mjl+1qeKmqyiSpIkSRqTDKjV1NYGzc1WUSVJkiSJEgNqRBwTESsj4omIOL+fa9oi4sGIWB4R9xQcXxURD/ecW1apgTeEXA4+/OGiVdRbb4VFi6o2MkmSJEkadYMG1IhoBq4APgDMBk6JiNl9rpkMXAkcl1LaD/hYn29zdEppTkqptSKjbiQLFmypojazmXwVNSU4+2yn+kqSJEkaO0qpoB4CPJFSejKltBG4CTi+zzWfAL6TUnoaIKX0YmWH2cByOfjbvyXHz7iSs4HuLae6upzqK0mSJGnsKCWgzgCeKXi9uudYobcBO0dER0TcHxHzCs4l4Ic9x9v7e5OIaI+IZRGxbM2aNaWOvzFMngwRtHMtJ3Ar2R9ZxoZJkiRJksaKUgJqFDmW+rxuAd4BfAh4P/BPEfG2nnOHp5QOJpsi/NcRcWSxN0kpLUoptaaUWqdNm1ba6BtFWxs0ZY9iAZcSdG051d0NN9xQpXFJkiRJ0igqJaCuBnYveL0b8GyRa+5IKb2WUnoJWAocCJBSerbn84vALWRThlWop1kSQI6fcTy3Ufh3AM8/X6VxSZIkSdIoKiWg3gfsHRGzImI8cDL0ajkLcCvw7ohoiYjtgEOBRyNi+4jYESAitgfeBzxSueE3kJ5mSZBVUVvYRD6k3n6703wlSZIkNb5BA2pKaTNwDnAn8Chwc0ppeUTMj4j5Pdc8CtwB/BL4OXBtSukR4K3AvRHxUM/x21NKd4zMj1Lncjm48kpoaiLHzziW7205tWmTzZIkSZIkNb5Iqe9y0uprbW1Ny5aN0S1TTzgBbr2Vs7iSq5lPfglwBFx9NbT322ZKkiRJkmpfRNzf3xakpUzx1WjadVcA5nEDTXSRn+abEpx1llN9JUmSJDUuA2qtmTdvyzTf4/os9e3udqqvJEmSpMZlQK01uRwcdxyQNUsqrKKC+6JKkiRJalwG1Fq0YMGWKupVnAV0kw+pVlElSZIkNSoDai0qqKK2cy0ncGuv07feCosWVWNgkiRJkjRyDKi1asECaGnJvuRSmtlMYcOks892qq8kSZKkxmJArVW5HBx7bPYlP+NKzibo3nK6q8upvpIkSZIaiwG1lk2fvuXLdq7leG7FhkmSJEmSGpUBtZb1bDmTl3X13VpF7e6G88+vxsAkSZIkqfIMqLWsoFkSZFN9j9v1vl6XLF0K55032gOTJEmSpMozoNa6BQtg3LitL188l4juXpdceqlTfSVJkiTVPwNqrcvl4EMf2vqy617O/R+39LokJRsmSZIkSap/BtR6UNAsCWDhkx/nyAPX9zrm3qiSJEmS6p0BtR7MmwfNzVtfd3dz8axrCvsnkRLMn29IlSRJklS/DKj1IJeDK6/c2tE3JXK3/yPHHbG212WGVEmSJEn1zIBaL9rb4cMf3vp60yYWcGlh/yQgC6lnnWXTJEmSJEn1x4BaT3bdtdfL3L2Xcs//eZjZs3tf1t1t0yRJkiRJ9ceAWk/mzaPXwtPubnIPXMm11/Y+DDZNkiRJklR/DKj1JJeD447rfez558nl4Kqreh92qq8kSZKkemNArTcLFkBLy9bXt98OnZ20t8MJJ/S+tLsbzj9/VEcnSZIkSUNmQK03uRwce+zW15s2bVlwumDBtlN9ly6F884bxfFJkiRJ0hAZUOvR9Om9X992G3R2Fp3qC1l+dT2qJEmSpFpnQK1HRZol5auo7e1ZJbUv90eVJEmSVOsMqPWoWLOknioqwMKFcOSRvU+nZEiVJEmSVNsMqPWq74LTPpufXnwxjBvX+xY7+0qSJEmqZQbUelWsilqw+WkuB/fcA7Nn977Ezr6SJEmSapUBtZ4tWADNzVtfpwRnn72lRJrLwbXX2tlXkiRJUn0woNazXA6uvLL3sa6uXlN97ewrSZIkqV4YUOtdezuccELvYwUNk/KX2NlXkiRJUq0zoDaCBQsgYuvr7m644YZel9jZV5IkSVKtM6A2glwOjj++97Hnn9/msosv3nY9qiFVkiRJUq0woDaKvg2Tbr99m/1k8utRDamSJEmSapEBtVHkcnDssVtfb9rUq1lSXns73HvvttvPuEeqJEmSpGozoDaSXXft/bpPs6S8/rafcY9USZIkSdVkQG0k8+b1Tp3d3UWrqLB1um9hbyXI9kg97bQRHKMkSZIk9cOA2khyOTjuuN7H+qmiQjbd9+qrtz2+eLEhVZIkSdLoM6A2mgULSq6iQv97pC5eDEcd5ZpUSZIkSaPHgNpoyqyiQrZH6qmnbnt86VI44gi7+0qSJEkaHQbURlRmFRXgxhuLh9TubregkSRJkjQ6DKiNqFgV9dZbB02ZN95YfLqv+6RKkiRJGg0G1Ea1YAE0N299nRKcffagi0oXLoRrrtm2u68hVZIkSdJIM6A2qlwOrryyd9Ls6hp0qi9s7e5rSJUkSZI0mkoKqBFxTESsjIgnIuL8fq5pi4gHI2J5RNxTzr0aIe3tcPzxvY8N0jCp8Nb+QuonPwnnnVfBcUqSJEkSJQTUiGgGrgA+AMwGTomI2X2umQxcCRyXUtoP+Fip92qEDaFhUl5/IRWyb+FeqZIkSZIqqZQK6iHAEymlJ1NKG4GbgD5lOT4BfCel9DRASunFMu7VSBrCtjOF8iG1qcg/KYsXG1IlSZIkVU4pAXUG8EzB69U9xwq9Ddg5Ijoi4v6ImFfGvRppw6iiQhZS770Xjjxy23OLF8OcOSXnXUmSJEnqVykBtcgET1Kf1y3AO4APAe8H/iki3lbivdmbRLRHxLKIWLZmzZoShqWSFauifve7ZaXKXA7uuaf4XqkPPQSHH27zJEmSJEnDU0pAXQ3sXvB6N+DZItfckVJ6LaX0ErAUOLDEewFIKS1KKbWmlFqnTZtW6vhVqr7bznR3Q0dH2d/mxhuLh1Q7/EqSJEkarlIC6n3A3hExKyLGAycDt/W55lbg3RHREhHbAYcCj5Z4r0ZDLgd/+7dbX6cE69YN6VsNFFLt8CtJkiRpqAYNqCmlzcA5wJ1kofPmlNLyiJgfEfN7rnkUuAP4JfBz4NqU0iP93TsyP4oGNXly75a8l1465JLnjTdmRdliLrnEdamSJEmSyhcpFV0SWlWtra1p2bJl1R5G4+nshHe/G7q6th6LyNr0trcP6VsuWgRnnZXNGO5rmN9akiRJUgOKiPtTSq3FzpUyxVeNIpeDD3+497GU4Oyzh1zuHKjDr+tSJUmSJJXDgDrWLFgA48b1PtbVVda2M30N1OHXkCpJkiSpVAbUsSafJmfP7n38ttuGvWi0v3Wp+eZJRx3lulRJkiRJ/TOgjkW5HFx7LTQVPP7u7mFVUfMWLoRrrundiylv6VL3S5UkSZLUPwPqWJXLwXHH9T5WgSoqZOtSr766d/7NcysaSZIkSf0xoI5lCxaMSBUVBm6eBNnbnHZaRd5KkiRJUoMwoI5lxaqot95asTm4+eWu/e2XunixIVWSJEnSVgbUsa5vFTWlbGPTCnYzGmhd6uLFMGuW61IlSZIkGVBVrIpawam+ee3t8JOfwJw5255btSpblzpnjl1+JUmSpLHMgKptq6hQsYZJhXI5eOCB4vulAjz0kF1+JUmSpLHMgKosOV51Ve9jI1BFzetvv1Swy68kSZI0lhlQlWlvhxNO6H1syZIRS4oLF8JPf1p8yi/Y5VeSJEkaiwyo2mrBAmhu7n3skktGLKTmp/wO1OXXBkqSJEnS2GFA1Va5HFx55bbtdi+9dES7Fw3U5dcGSpIkSdLYYUBVb+3tcO65vY+lBOefP+Jv21+XX8gaKB12mGtTJUmSpEZmQNW2Fi6EI4/sfWzp0hFPh4NN+YVsxrHVVEmSJKkxGVBV3MUXj/pU37zBGijlt6OxmipJkiQ1FgOqisvlqjLVt/DtB6qmpmQ1VZIkSWo0BlT1r0pTffsOYbBqqmtTJUmSpMZgQNXA+pvqO4p7v+SrqddcA3vuWfwaq6mSJElS/TOgamD9TfWdP3/UNyhtb8+2nTn11OLn89XUE080qEqSJEn1yICqwS1cuO1i0JTgrLOqkgRvvHHgTr9LlthESZIkSapHBlSVZuFCOOGE3se6u0etaVKx4Qy0NtUmSpIkSVL9MaCqdAsWQFOff2RGuWlSocJOv32XyebZREmSJEmqHwZUlS6Xg6uu2vb4JZeM+nrUQgsXwk9+sm2Bt9All8CsWVUdpiRJkqRBGFBVnvb24gtAq7QeNS+Xg1tuGXja76pV8MlPwq67GlQlSZKkWmRAVfmK7Y9axfWohQqn/fbn+eezoOr6VEmSJKm2GFA1NBdfXFPrUfvKN1Hqm6MLuT5VkiRJqi0GVA3NQOtRayTx5XJwzz0DT/uFbMi77ur+qZIkSVK1GVA1dP2tR73kEjjttNEfTz/y036vuQamTy9+zfPPZ/unWlGVJEmSqseAquFZuLB4SF28uOaSXns7PPfcwOtTwf1TJUmSpGoxoGr4+gupVd5+pj/lrE/db7+a/BEkSZKkhmRAVWUsXAinnrrt8fnzazLhFa5PHSiorlhhx19JkiRptBhQVTk33rht2kup6nukDqTURkr5iupRR9XsjyJJkiTVPQOqKqvY9jPd3fCXf1nTya5w/9SI/q9butRGSpIkSdJIMaCqsvLbz/RNeStWwBFH1OR030ILF8JPfpLNTN577/6vc2saSZIkqfIMqKq89na4+uptQ2p3d01P983LZ+zHHhu442/h1jRO/ZUkSZKGz4CqkTFQSD3//OqMaQhK6fgLTv2VJEmSKsGAqpHTX0hduhROO606YxqCUjv+glN/JUmSpOEwoGpk5UNqX4sX1125sdSgWjj1t85+REmSJKmqDKgaee3txRdzXnJJzTdNKmYoFdU6/DElSZKkUWdA1ehYuBBOPXXb4/Pn1216K6ei+slPZvusOu1XkiRJ6l9JATUijomIlRHxRERs0+EmItoiYn1EPNjz8fmCc6si4uGe48sqOXjVmRtv3DbJpZSltzqeC1tqUH3ooWza76xZdZvJJUmSpBE1aECNiGbgCuADwGzglIiYXeTS/0opzen5+FKfc0f3HG8d/pBV1y6+GJqK/GN3ySV1HVKhd1CdM6f/61atyjK5U38lSZKk3kqpoB4CPJFSejKltBG4CTh+ZIelhpXfZLS/kNoAiS2XgwcegGuugenT+7/Oqb+SJElSb6UE1BnAMwWvV/cc6ysXEQ9FxA8iYr+C4wn4YUTcHxHtwxirGkV7O9x7b/H5sHW8JrWv9nZ47rksqO65Z//X5af+HnWUQVWSJEljWykBNYocS31e/wLYM6V0IPBvwJKCc4enlA4mmyL81xFRdJVeRLRHxLKIWLZmzZoShqW6lp8PW2xNagOFVMiC6qpVg1dUly41qEqSJKk0ixbB+9+frZI78USYOTNbQjZrVva6Xn+fjJT6Zs0+F0TkgC+mlN7f8/oCgJTSRQPcswpoTSm91Of4F4HfpZQuG+g9W1tb07Jl9lMaEzo74YgjoLu79/GIbP/U9sYrui9aBF/4QjbFdyALFmTNjyVJklRbFi2Cyy+H11+HyZPhlVfgzTd7XzNxYvFz/R0vdq67O6vfjB8P228Pr74KGzfCG2/A738/8BjHjcvqQbncsH/ciouI+/vrT1RKQG0BHgPmAr8F7gM+kVJaXnDNdOCFlFKKiEOAbwF7AtsBTSmlDRGxPfAj4EsppTsGek8D6hizaFFWNe37z2IDh1TIfuyvfAWeeqr/a/7H/4D3vhfmzavN/7hIkiSNtM7OrFXJAw+MTAgc6HhhQNxxxywgrls3eDisFV/5ClxwQbVHsa2BAmrLYDenlDZHxDnAnUAz8LWU0vKImN9z/mrgo8BZEbEZeB04uSesvhW4JSLy7/Wfg4VTjUH5ANo3pOan+xZe00Da27OP887L/qNbzBNPZB/XXAPnnmtFVZIklaZYqKtUaBvOuYkTYaedspBXWCFMCSZMgB122FolTAk2bYINGyrxJzL2jBsHbW3VHkX5Bq2gVoMV1DFqjFZSIfufyPnnZ+tQBzJ9OvzP/9nQfxSSJNWtRYvguuuycDXSIXDcOJg0aWvQg61BD+Dllyv7s6n2TZmSVXonTsx2iViwoHZn4A1rim81GFDHsEWL4KyzxtSa1EKdnXD22fDggwNfd+CB2W49tfofHUmSalnf6uJQguP48Vm1b/36bD3g66/Xz7RPVc6UKbDHHiP/FxLFjk+ZAgcdBGvWwEc+Ul+/JhtQVV86O+Ev/xJWrOh9fIyEVNi68P7RRwe+bubMbF3BGPgjkSRpS7BcuTKbDlrOL/gTJmQVx+eeg5deQnUoXyEsNNIhsL9zU6bAZz7j72BDZUBV/RmD3X2LKbWi6tRfSVI9KGddZOHx11/Pzq1fX41R17/CqZ+1sAa13HsMg43HgKr6NIbXpPZV6tY0BlVJ0kgbSkfVceOy/30//fSoDrVqZsyAlpbRn/JZeG6PPWD2bHcCUG0yoKp+9RdSYUxuFFrK1jSQBdV3vau2F8dLkkZWYZCMGHowevnlrIKZUtb859VXR/GHGAVTpmRTfysRHK30SaUxoKq+DRRSTz0Vbrxx9MdUZaVWVAGOPBIuvtigKkn1YqidYCdMyPZpfOUV+N3vGn867N57Z39GQ6k4RtR+l1OpkRlQVf/66+4LYzakQnlBdc6crKrqVB9Jqox8Q7tXXsleD3f65u9/n3289trojL/aBlsXWex4PWyfIWlwBlQ1hoE2Cx3DIRVKn/qbZ/dfSWPBUCuR/Z3r7s7WUm63XfYXgxs2jMZPUbuG0lH1zTdhn30MmNJYZ0BVYzntNFi8eNvjYzykwsAZvpgpU7IpwP6iIKla+lYhofxKZHd3FpR23DFbH/nmm1urkcpMn5592FFVUi0woKrxGFIHVG5QhewXF3/pkDRU/XV27S/kNDdnlc01a0Z9qHVjuJ1gnQ4rqVYZUNWY+gupdgXaovAXxlKn/4KVVWmsKndKbErQ1ZV9Xru2KkOuCTvuCNtvX7ktRPzLQkmNzoCqxtVfSG1qgquu8v/uBfJhdenSbMuAUtlcSapvxabQwrbB6LXXGndNZbmVyIHOFR7ffnuDpCQNhQFVja2/kBoBV1/tbw5FlNtUKc/9VaXqK3XNZnd39nW9bDWSr0KClUhJanQGVDW+887LyoN9GVIH1NkJN9wAK1bAI49YWZWqodStSsaNg02bSttWqtoKu7sOFjbHj4e/+Av/My1JY4kBVWPDokUwf362GKqvBQtg4cLRH1OdsbIqVUY+dL7+ev/hbIcd4JlnarPCOZTmPHvsAbNn+5dWkqTBGVA1dgwUUm2eVLKhNlcC91hV4+vbrbZe1nL23bPSKbGSpGoxoGpsGSik2jypbPlfxn/2s/KmFk6ZApMmucWB6lN/026few5eeKGaI9uq1DWb/jsoSao1BlSNPQOFVHDK7xANp7JqAVu1pL/OthMmwBtvVCeElrpViWs2JUn1zoCqsamzE84/P9tXpZhTT4UbbxzdMTWQoVZWZ860oqPRUyyIvvEGrFs3Ou8/ZUq2NtOtSiRJ2sqAqrFtoGqqIbUihhpWrapquPquB81LKWtQ9OqrI/v++ansruWUJKl0BlRpoJB64IHZulRTUkUMJazaWEn9yf/ztHJlNv22MAS+/vrId8AtNu02wlkAkiQNhwFVguw33bPPhgcf3PZcBJx7rutSK2ywWdZ9TZmSbVlj5WnsKJyC23ft5WgE0P4627rOU5KkkWNAlQqddhosXlz8nFN+R0RnJ9xwQ1ZVLfb3A8VMmZJNAbZKVf+KdcSdNClrtDVae4AWBlE720qSVF0GVKmvgUKqU35HVLlVVbCxUj3Jh9HXX88qkU8/DS+/PPLv27cSCgZRSZJqlQFVKmbRIvjKV4rvlxIBV1/t/L4RNNTGStOnw7veZeioBYsWwXXXwcaNWXV07Vr43e9G7v323jt7r8JmSDYjkiSp/hhQpYEMVE094QST0CjIh9WlS8urtu29N+y8s2sFR0vhVN3XXoMNGyr3vXfcEaZO3bYbrlVQSZIajwFVGsxAIbWpKZvyawIaFQMVtgeSDziGmcro27zojTfKq3QXU6wjrnuASpI09hhQpVKcd15WxuvPggV2+R1FQ2msVGj6dKtvpSjcRzQiC45PPbW1odFQTZkCe+xhCJUkSdsyoEqlWrQIzjoLuruLn7fLb1UMdb1qoSlTss6xYy2wFuugm69erltXmS66M2ZAS0s2Ldc1oZIkaTAGVKkc+TS0ZEnx83b5rar841m5MlsDuXr10L5Po2w70jeA5k2YkAXG4U7LLSY/VdcwKkmShsKAKg3FokUwfz4U+3fELr81Ix/QXnihMtuZ9N2uZOLEbKrq7Nkwb97oBNi+6z/7Ng6C7B/LN94Y+X1EC5sXjR9vQypJkjR8BlRpqDo74eyz+18EeeSRcPHF9Vd2a1D5dasrVsBjj41M9TAfYPsLjtD/uYHuGTcOdtgBfvtbePXVyo+7FNOnZx+uG5UkSSPJgCoN10Bdfq2m1qzCBkBvvpntoVmJKms9KtZB980363t6syRJqk8DBdSW0R6MVJduvDHrBHPppdtO+U0JPvlJ+PWv7fJbY3I5uOWW3seKrdlshOBabGqy03IlSVK9sYIqlaOzE84/H5YuLX7eBkp1q79mQzAyU4VLUbj+s7+pxFY/JUlSvXGKr1Rpg+2Z6trUhtJ3qjBUfg1q4TnXf0qSpEZmQJVGwkBdfvMWLHDaryRJklRgoIDaNNqDkRpGezv85CfZHMv+XHJJdr6zc7RGJUmSJNUtA6o0HLlcNu/zmmtgzz2LX/PQQ3D44VnFVZIkSVK/DKhSJbS3w6pV2ZTeYvKdfk880WqqJEmS1A8DqlRJCxfCT3/a/7TfJUuyaup5543mqCRJkqS6YECVKi0/7XegaqprUyVJkqRtGFClkbJwYbY2tamff80eeggOO8xqqiRJktSjpIAaEcdExMqIeCIizi9yvi0i1kfEgz0fny/1XqmhtbfDvffCCSf0f80ll8CsWTZRkiRJ0pg3aECNiGbgCuADwGzglIiYXeTS/0opzen5+FKZ90qNK5eDW24ZeG3qqlVZEyWn/UqSJGkMK6WCegjwRErpyZTSRuAm4PgSv/9w7pUay2BrU8Fpv5IkSRrTSgmoM4BnCl6v7jnWVy4iHoqIH0TEfmXeS0S0R8SyiFi2Zs2aEoYl1al8p98jj+z/GpsoSZIkaQwqJaBGkWOpz+tfAHumlA4E/g1YUsa92cGUFqWUWlNKrdOmTSthWFIdy+XgnnsGnvabr6but5/rUyVJkjQmlBJQVwO7F7zeDXi28IKU0qsppd/1fP19YFxE7FLKvdKYVsq03xUrXJ8qSZKkMaGUgHofsHdEzIqI8cDJwG2FF0TE9IiInq8P6fm+a0u5VxJbp/32V00F16dKkiSp4Q0aUFNKm4FzgDuBR4GbU0rLI2J+RMzvueyjwCMR8RDwVeDklCl670j8IFLdK6ymRrHZ8T1cnypJkqQGFSkVXRJaVa2trWnZsmXVHoZUPZ2dcMMNcPfd8Pjj/V83cyZccEG236okSZJUByLi/pRSa7FzpUzxlTTacjm46ip47LGB16e6f6okSZIaiAFVqnXlrE896iiDqiRJkuqWAVWqB/n1qddcA3vu2f91S5dmQfXEEw2qkiRJqjsGVKmetLdn03qvuQamT+//uiVLrKhKkiSp7hhQpXrU3g7PPTfw+lTYWlE1qEqSJKkOGFClepZfn3rkkQNflw+q++0HixaNztgkSZKkMhlQpXqXy8E992RB9YQTBr52xYqs6++uuxpUJUmSVHMMqFKjyOXglltKq6g+/3wWVKdOtaGSJEmSaoYBVWo0hRXVwYLqyy9vbajk9F9JkiRVmQFValSFQXX+fNh774Gvd/qvJEmSqsyAKjW6XA6uugoee2zw7WnA6b+SJEmqGgOqNJbkt6e55hrYc8+Br3X6ryRJkkaZAVUai9rbYdWq8qf/WlWVJEnSCDKgSmNZudN/C6uqRx1lUJUkSVJFGVAlZcqZ/guwdGkWVHfd1aqqJEmSKsKAKqm3cqf/Pv+8VVVJkiRVhAFVUnF9p/+WU1U96CA46yzDqiRJkspiQJU0uMKq6gknDL5W9cEH4eqrs7A6a5YdgCVJklQSA6qk0uVycMst5a1VXbXKDsCSJEkqiQFV0tAUVlWPPHLw6ws7AFtVlSRJUhEGVEnDk8vBPfdsnf5bTlV1110NqpIkSdrCgCqpMvLTfwvXqk6ZMvA9zz/v9F9JkiRtYUCVVHn5sLp2bbZWdd99Bw6rTv+VJEkSBlRJI629HVas2BpWB+sAbFMlSZKkMcuAKmn0tLdv7QA8WFDtW1U1rEqSJDU8A6qk0VcYVAeb/gtZVTUfVnfd1bAqSZLUoAyokqqn3Om/kDVWyofVgw6Cs84yrEqSJDUIA6qk2lBYVS1lqxqABx+Eq6+2uZIkSVKDMKBKqi3t7Vu3qpk/H+bMKe0+mytJkiTVPQOqpNqUy8FVV8EDD2zdV7WUKcCFzZWmToX99rOyKkmSVCcMqJJqX35f1eee2xpWS5kG/PLL2RpXK6uSJEl1wYAqqb7kw2p+GvAJJwzeBRjctkaSJKkOGFAl1a98WM13AS5lyxrovW2N04AlSZJqhgFVUmPou2XNvvvCjjsOfl/facBWVyVJkqrGgCqp8eTD6quvlrdtzcsvb1tdNbBKkiSNGgOqpMY21G1rwMAqSZI0yiKlVO0xbKO1tTUtW7as2sOQ1Kg6O+GSS7ItbDZsyILoUOy9N2zcCNtvD5/5TBaGJUmSNKCIuD+l1Fr0nAFV0piXD6w/+xk8//zQv8+OO2ZhdeLErFK7YEHWyEmSJElbGFAlqVSF1dU338wqpEOtsELWVXj8+K1fW2mVJEljnAFVkoZj0SK4/HJ44YXhhdW8wtBqtVWSJI0xBlRJqpR8hXXlSpgwAZ5+ujKhFbauaX3zTautkiSpYRlQJWkk5Susr7ySvR7utOBCU6bAHntk39tmTJIkqQEMO6BGxDHAvwLNwLUppYv7ue6dwM+Aj6eUvtVzbBWwAegCNvc3kEIGVEl1byRDq82YJElSHRtWQI2IZuAx4E+A1cB9wCkppRVFrvsR8AbwtT4BtTWl9FKpAzagSmpIlW7AVMhmTJIkqU4MFFCbSrj/EOCJlNKTKaWNwE3A8UWu+xTwbeDFIY9UkhpZLge33AKrVsFzz8HatfDTn8IJJ8C++2bV0D33zCqk5Xr55WyLnOefhxUr4JOfhN12g5kzYdddYdYsOPHELCRLkiTVqJYSrpkBPFPwejVwaOEFETEDOBF4D/DOPvcn4IcRkYBrUkqLhj5cSWow+dDaV36K8Ouvw+TJQ2vG9Nvf9n69ahUsWdK7GRNYcZUkSTWjlApqFDnWd17w5cB5KaWuItcenlI6GPgA8NcRcWTRN4loj4hlEbFszZo1JQxLkhpYe3tWCf3Nb7IpwWvXwjXXZJXW6dOzjylThva9H38cnnpq24rr1Klw0EFZ1dWKqyRJqoJS1qDmgC+mlN7f8/oCgJTSRQXX/IatQXYX4PdAe0ppSZ/v9UXgdymlywZ6T9egSlKJ+jZjeu012LChsu+RD8Rvvgn77GNTJkmSNCzDbZLUQtYkaS7wW7ImSZ9IKS3v5/rrge+llL4VEdsDTSmlDT1f/wj4UkrpjoHe04AqScOwaBFcd102jfeVV7LAWqlmTHn5pkx2EpYkSWUaKKAOugY1pbQ5Is4B7iTbZuZrKaXlETG/5/zVA9z+VuCWiMi/138OFk4lScPU3r7tetJ8B+GVK2HChCy4vvnm0CuuhYE3v7bVTsKSJGmYStoHdbRZQZWkUdS3IVN+bWolFIbW/GuDqyRJY9qwpvhWgwFVkqqscM/WCBg3LmuuVCkzZkBLy9ZOwk4VliRpzDCgSpKGrzC05oPlxo2VX986fXrv11ZdJUlqKAZUSdLI6dtJeCRCK2xbdQUrr5Ik1SEDqiRpdBWrto7EFjiF+q53nTgR9tgDZs+GefMMsJIk1QgDqiSpNvTdAufNN0eu4tpX4dY4kye7r6skSVViQJUk1bbOTrjhBlixAp56avSqrnmGV0mSRo0BVZJUv4pVXfNGo/o6ZQpMmpQF177vbwMnSZLKZkCVJDWuvk2aClVqP9fBFGvgBFsrsuPHw1/8hUFWkiQMqJKksapYs6aJEyu/r2updtwRtt9+a3AtrMjakViSNEYYUCVJ6qvWwmuhPfeElLIpzHmGWklSgzCgSpJUjr7htVg4HK0GTqXaay/o6tp2n1jXzkqSaowBVZKkkTBQAyfIAuLmzbB6dXXGN5jp07P1sYNVagvPWbGVJA2TAVWSpGrq28ipbwgcrb1gK2mnnWDCBGhqGjzUWsWVJBUwoEqSVOvy04pXrsyCX99A1wihtpiddsqquBFZ2IX+Q23f41Z0JakuGVAlSWpE5YZaqL21s5UybVo2ZfnVV0tbh5s/Z8CVpFFnQJUkSVsNtHZ2oEDXKFXbYiZPzn72vFKquNtv7zRlSRoCA6okSaqMvutpofw1qI0WdAfa3xa2Pe76W0ljnAFVkiTVlmL70OaVEvQ2bKj/kLvDDrDzztnH+vWlV7KnTIFjj83Ot7U5PVlS3TGgSpKkxlMYciNKq14WapRK7pQpWaOpUirZb74J++zjultJVWVAlSRJKqbYlGUYvIr79NP1H26nTIFJkwYPtePHw1/8hVOSJVWMAVWSJKnSBtvfNq/w+Msv128X5cHW2oKVWkklMaBKkiTVisJgW2pjpbx6nJY8eXK23+3OO5feSMstgKSGZkCVJElqFJ2dcMMNsGIFPPVU71A3UGVz3Dh4/PFRH+6w7bILNDVlH3mldo6OMOhKNciAKkmSpG27Jw8W9DZvhtWrqzLUittlF3jLW+B3v8sq0YXKrWRb4ZWGxYAqSZKkoSl1rW3+XL1Waoeqb4W33H2Bix2fOBH22ANmz4Z58wzBajgGVEmSJI2eciu1hefqcZ3tSJs5E7q6YNOmrccqEYSnTIHPfMYOzRp1BlRJkiTVj/7W2eaVEs6efz770OB22CFrZDV5ctZlunAK9FCD8B57ZAF4+nSrwNqGAVWSJEljT2ElN2L4FUewwjtUO+8MEyY4BVqAAVWSJEmqnIEqvMMNYBs2GIDLteee0N297RTonXaCdeuG9xcS4FToEWBAlSRJkupFYQBesyarPJYapgY6V3j85ZezMKzSTZsGLS1ZEI7Ijm23XXl7/A50PH9ujz2yr9esgX32achu0QZUSZIkSb0VdmgeapgqNgX6lVegBjNGXctvk7RhQ+9KMRSfAl3j2yAZUCVJkiSNjs5O6OiAqVPhBz/Y2s0ZnAI9msaNg3vuqcmQOlBAbRntwUiSJElqYLnc1lA0Eus2R2MKdP74a6/V71ToTZuyvyiowYA6EAOqJEmSpPpRGIBHw6JFcN11W6cvj0QQLvTii1nTp+EaNw7a2ob/fUaZAVWSJEmS+tPeProdfItNkS5nm6Q6WIM6ENegSpIkSZJGzUBrUJtGezCSJEmSJBVjQJUkSZIk1QQDqiRJkiSpJhhQJUmSJEk1wYAqSZIkSaoJBlRJkiRJUk0oKaBGxDERsTIinoiI8we47p0R0RURHy33XkmSJEnS2DZoQI2IZuAK4APAbOCUiJjdz3ULgTvLvVeSJEmSpFIqqIcAT6SUnkwpbQRuAo4vct2ngG8DLw7hXkmSJEnSGFdKQJ0BPFPwenXPsS0iYgZwInB1ufdKkiRJkgSlBdQociz1eX05cF5KqWsI92YXRrRHxLKIWLZmzZoShiVJkiRJaiQtJVyzGti94PVuwLN9rmkFbooIgF2AD0bE5hLvBSCltAhYBNDa2lo0xEqSJEmSGlcpAfU+YO+ImAX8FjgZ+EThBSmlWfmvI+J64HsppSUR0TLYvZIkSZIkQQkBNaW0OSLOIevO2wx8LaW0PCLm95zvu+500HsrM3RJkiRJUiOJlGpvNm1ra2tatmxZtYchSZIkSaqwiLg/pdRa7FwpTZIkSZIkSRpxNVlBjYg1wFPVHscAdgFeqvYgVDKfV/3xmdUXn1d98XnVH59ZffF51RefV3XsmVKaVuxETQbUWhcRy/orSav2+Lzqj8+svvi86ovPq/74zOqLz6u++Lxqj1N8JUmSJEk1wYAqSZIkSaoJBtShWVTtAagsPq/64zOrLz6v+uLzqj8+s/ri86ovPq8a4xpUSZIkSVJNsIIqSZIkSaoJBtQyRcQxEbEyIp6IiPOrPR5BROweET+OiEcjYnlEfKbn+JSI+FFEPN7zeeeCey7oeYYrI+L91Rv92BURzRHxQER8r+e1z6tGRcTkiPhWRPyq59+znM+rdkXE3/T8t/CRiPhGREz0edWWiPhaRLwYEY8UHCv7GUXEOyLi4Z5zX42IGO2fZSzo53ld2vPfxF9GxC0RMbngnM+ryoo9s4JzfxcRKSJ2KTjmM6shBtQyREQzcAXwAWA2cEpEzK7uqARsBv42pbQv8C7gr3uey/nA3SmlvYG7e17Tc+5kYD/gGODKnmer0fUZ4NGC1z6v2vWvwB0ppT8GDiR7bj6vGhQRM4BPA60ppbcDzWTPw+dVW64n+/MuNJRndBXQDuzd89H3e6oyrmfbP9sfAW9PKR0APAZcAD6vGnI9Rf58I2J34E+ApwuO+cxqjAG1PIcAT6SUnkwpbQRuAo6v8pjGvJTScymlX/R8vYHsl+cZZM/m33su+3fghJ6vjwduSim9mVL6DfAE2bPVKImI3YAPAdcWHPZ51aCImAQcCVwHkFLamFJah8+rlrUAfxARLcB2wLP4vGpKSmkp8HKfw2U9o4jYFZiUUupMWUORGwruUQUVe14ppR+mlDb3vPwZsFvP1z6vGtDPv2MA/wIsAAqb8PjMaowBtTwzgGcKXq/uOaYaEREzgYOA/wbemlJ6DrIQC7yl5zKfY/VdTvY/iO6CYz6v2rQXsAb4es+U7GsjYnt8XjUppfRb4DKy6sBzwPqU0g/xedWDcp/RjJ6v+x7X6DsT+EHP1z6vGhURxwG/TSk91OeUz6zGGFDLU2zeuW2Qa0RE7AB8G/hsSunVgS4tcsznOEoi4ljgxZTS/aXeUuSYz2v0tAAHA1ellA4CXqNn6mE/fF5V1LNu8XhgFvCHwPYRcdpAtxQ55vOqLf09I59dDYiIfyBbarQ4f6jIZT6vKouI7YB/AD5f7HSRYz6zKjKglmc1sHvB693Ipk6pyiJiHFk4XZxS+k7P4Rd6pmfQ8/nFnuM+x+o6HDguIlaRTZN/T0TciM+rVq0GVqeU/rvn9bfIAqvPqza9F/hNSmlNSmkT8B3gMHxe9aDcZ7SardNKC49rlETE6cCxwKlp676NPq/a9Edkf3H3UM/vH7sBv4iI6fjMao4BtTz3AXtHxKyIGE+2oPq2Ko9pzOvpqHYd8GhK6Z8LTt0GnN7z9enArQXHT46ICRExi2zR+89Ha7xjXUrpgpTSbimlmWT/Dv2/lNJp+LxqUkrpeeCZiNin59BcYAU+r1r1NPCuiNiu57+Nc8nW5fu8al9Zz6hnGvCGiHhXz7OeV3CPRlhEHAOcBxyXUvp9wSmfVw1KKT2cUnpLSmlmz+8fq4GDe/4f5zOrMS3VHkA9SSltjohzgDvJOiN+LaW0vMrDUlaR+zPg4Yh4sOfY3wMXAzdHxF+Q/dL2MYCU0vKIuJnsl+zNwF+nlLpGfdTqy+dVuz4FLO75i7kngT8n+wtOn1eNSSn9d0R8C/gF2Z//A8AiYAd8XjUjIr4BtAG7RMRq4AsM7b+BZ5F1K/0DsjWQP0AV18/zugCYAPyoZ+eRn6WU5vu8akOxZ5ZSuq7YtT6z2hNbZyRIkiRJklQ9TvGVJEmSJNUEA6okSZIkqSYYUCVJkiRJNcGAKkmSJEmqCQZUSZIkSVJNMKBKkiRJkmqCAVWSJEmSVBMMqJIkSZKkmvD/AaHz4sTwkbuBAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist.history[\"loss\"])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(range(n), run_hist.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABCa0lEQVR4nO3deXhU5fn/8fdN2MIiCAjKLoK4tIiCUhUliigiqLVurSJ+Fa222mqRHcUFEMT1Vym4odXWDbWIiIKKERVRQdn3fQmr7Ekg2/P7Y4Y2hECGZGaeWT6v68pFZs6Zcz7zZJh77nPOnGPOOURERCR2lPMdQERERA6m4iwiIhJjVJxFRERijIqziIhIjFFxFhERiTEqziIiIjFGxVmSjpmlmtlHZrbLzMb5zpOszOw1MxsS/P0CM1sS4uNuNbNvIpvOr5Keo5mlm1nPaGaS6FJxTnBmttrMss1sr5ltCr4hVisyz3lmNtXM9gQL1kdmdlqReY4xs2fNbG1wWcuDt+scZr1mZn8xs/lmlmlm681snJn9OpLPN0TXAvWA2s6568q6MDNLMzNnZqOK3P+Nmd0a/P3W4Dy9i8yz3szSypohhIyFXwebzezVA6+Dwm/0hZ7LB0Uef0bw/vQi95uZrTSzhWXJ55z72jnXsizLCEUyFHZJDCrOyaGbc64a0Bo4E+h/YIKZnQtMAT4E6gMnAnOAb82sWXCeisAXwOlAZ+AY4DzgF+Ccw6zzOeCvwF+AWsDJwHjgiqMNb2blj/YxJWgCLHXO5YUxSyZwi5k1PcLDtwN9zeyYo11vmBx4HZwFnA0MOsx8W4HzzKx2oft6AEuLmfdCoC7QzMzODmfYRBaB17QkGBXnJOKc2wRMJlCkD3gCeN0595xzbo9zbrtzbhAwA3g4OM8tQGPgt865hc65AufcFufcY865SUXXY2YtgD8Dv3fOTXXO7XfOZTnn/u2cGx6c56DNckU7mmCX9mczWwYsM7MxZvZkkfV8aGZ/C/5e38zeN7OtZrbKzP5S3BiY2SPAQ8ANwS7ydjMrZ2aDzGyNmW0xs9fNrEZw/qbBLLeb2Vpg6mGGdyfwGjD4MNMBFgHfAfcfYZ7CWWsEs2wNZhtkZuWC024NduZPmtmO4HO+PJTlOuc2AJ8AvzrMLDkEPkjdGFxXCnA98O9i5u1B4IPdpODvR3o+Z5rZT8EtNO8AlQtNSzOz9YVu9zOzFcF5F5rZbw9dnP09uKVnsZl1LDShhpm9YmYbzWyDmQ0xsxQzOxUYA5wb/NvvDM5fKTiOa4NbFcaYWWpwWh0zm2hmO81su5l9feBvUMzzcxbYWrTSzLaZ2cgif69vzewZM9sOPHykv29Jz7GYdd9mZouCr4XJZtakSK4/mdmy4Hg+ZmYnmdl3ZrbbzN61wAdwiSEqzknEzBoClwPLg7erEOiAi9vv+i7QKfj7JcCnzrm9Ia6qI7DeOfdD2RJzNdAOOA14k0BBNQAzOxa4FHg7+Ib2EYGOv0Fw/feZ2WVFF+icGwwMA95xzlVzzr0C3Br8uQhoBlQDni/y0A7AqcAhyyxkKPA7MzvS5tkHgfvNrNYR5jng70CNYKYOBD4k/V+h6e2AJUAdAh+yXjkwPkdiZo2ALsDPR5jt9eD6IPCcFwAZRZZThcAugn8Hf2483Jt88P7xwBsEtqSMA353hPWvAC4g8PwfAf5lZicUmt4OWEnguQ8GPig0pv8E8oDmBLYUXQr0dM4tAu4Cvgv+7WsG5x9BYMtO6+BjGhD4AAfQC1gPHEdgV8gA4EjnPP4t0JbA1omrgNuKyVyXwGsllL/v4Z7jf5nZ1cFc1wRzfg28VWS2zkAb4DdAH+BF4CagEYEPab8/wnMSD1Sck8N4M9sDrAO28L/urhaB18DGYh6zkcCbAkDtw8xzOEc7/+E8Huzkswm84TgCb9gQKArfOecyCGyiPc4596hzLsc5txJ4iWDnF4KbgKedcyuDH0D6Eyg0hTc9PuycywxmKVZwy8QY4NEjzDObwG6EvkcKFOxWbwD6B7dorAaeAroXmm2Nc+4l51w+gYJ0AoECcjjjg93iN8BXBD6kHC7ndKBW8IPGLQSKdVHXAPuDz2ciUJ7D77b4DVABeNY5l+ucew/48QjrH+ecywhupXkHWMbBu1C2FFrWOwQ+pFxhZvUIfAC9L/j32gI8w2FeC8EPM3cA9wdfa3sIjMuB+XMJjGuT4Lq+dke+IMGI4HLWAs9ycNHLcM79Pbg7JYeS/77FPsdi1vlHAv9XFgWXPQxoXbh7Duba7ZxbAMwHpgRf77sIbEU58wjPSTxQcU4OVzvnqgNpwCn8r+juAAoIvPkUdQKwLfj7L4eZ53COdv7DWXfgl+Ab4tv8783uD/xvM2sToH5w0+POYAEawJELVWH1gTWFbq8hUGgKP34doRkBXGZmZxxhnoeAu83s+CPMUweoWEyuBoVubzrwi3MuK/jrQQf7FXG1c66mc66Jc+5PR/qgEfQGcA+BLQr/KWZ6D+Bd51yec24/8AGH37RdH9hQpLCtOcy8mNktZja70N/zV/zvdcthllWfwGuhArCx0GNfINCtFuc4oAowq9D8nwbvBxhJYEvTlODm6n6HyxxU+HVyIFNx00L5+x7uORbVBHiuUP7tgBVZ1uZCv2cXc/tIrxvxQMU5iTjnviKwX/TJ4O1MAvtAizti+XoCB4EBfE6g4FQNcVVfAA3NrO0R5skk8KZ4QHGFqmiH8hZwbbAjaAe8H7x/HbAqWHgO/FR3znUJMW8GgTe4AxoT2Cxa+A0spMu3Oed+IdAxPXaEeRYTKGQDjrCobQS6tqK5NoSSI0zeAP4ETCpU/IH/7iK5GLjZAt8C2ERga0YXK/4I/o1AgyKb3RsXt9Lg3/clAh8Magc3P88nUHAOKG5ZGQReC/uBOoVeC8c4504Pzlf077iNQHE6vdD8NYIHzhHsans555oB3YC/HWnfL4HNxEUzHVB43aH8fQ/3HItaB/yxyOs/Nbj1Q+KUinPyeRboZGatg7f7AT2CB7JUN7NjLfDd03MJ7OuDwJv0OuB9MzvFAgdQ1TazAWZ2SAF0zi0D/gG8ZYEDfSqaWWUzu7FQ5zEbuMbMqphZc+D2koI7534mcCTxy8Bk59zO4KQfgN1m1tcC32FOMbNfWehHD79FYD/wiRb4etGBfdJHfTR30NME9uWfeoR5HiGwf7FmcRODm6rfBYYG/y5NgL8B/yplpqPmnFtFYF/owGImdydw9HZLAvtqWxPYb7ue4vdffkfgA89fzKy8mV3D4Y/0r0qgkG0FMLP/49CD1+oGl1XBzK4jMNaTnHMbCWxmf8oCX/8rFzz4qUPwcZsJfHCsGHyOBQQ+CDxjZnWD62tw4HgFM+tqZs2DRXI3kB/8OZzewf9DjQh8W+Gd4mYK8e9b7HMsZnFjgP5mdnowc43g/BLHVJyTjHNuK4H9hw8Gb39D4ICfawh0N2sI7H9qHyyyBDdZXgIsBj4j8Cb1A4FNc98fZlV/IXBQ1SgCRzKvIHCwzEfB6c8Q2O+2mcD+0uKOBC7OW8EsbxZ6TvkEuprWwCoCXcnLBA62CcVYAh9ApgUfvw+4N8THHsI5t5vAAVqHPegrWPjeIFCIDudeAlsYVhLYT/xmMGvUOOe+Ce7XL6oH8A/n3KbCPwQKxSGbtp1zOQReY7cS2J1yA4GtB8WtcyGB/a/fEXh9/Br4tshs3wMtCPythwLXBrdaQGAfeUVgYXBd7/G/3SxTCRzctsnMDuy26Utg0/UMM9tNYEvRgYP6WgRv7w3m+YdzLr243EEfArMIfPj8GHjlCPOW9Pc90nP8L+fcfwjsTnk7mH8+gf3uEsfsyMc2iIhIKMzMAS2cc8t9Z5H4p85ZREQkxqg4i4iIxBht1hYREYkx6pxFRERijIqziIhIjCnxyihmNhboCmxxzh1yovzg9/+eI3Cu3izgVufcTyUtt06dOq5p06YH3ZeZmUnVqqGe50KOhsY2sjS+kaOxjSyNb+QUN7azZs3a5pw77jAP+a9QLlv2GoHvqxZ3bl0IfJ+uRfCnHTA6+O8RNW3alJkzZx50X3p6OmlpaSFEkqOlsY0sjW/kaGwjS+MbOcWNrZkd9rS1hZW4Wds5N43AuVoP5yoClxx0zrkZQM0iV48RERGRoxCOC3434OATuq8P3heOqxKJiIhE1DvvvMP06eE/FXlGRkapt0qEozgXd/3YYr+fZWZ3AncC1KtXj/T09IOm792795D7JDw0tpGl8Y0cjW1kaXzhvvvuY9u2bVSuXDlsy8zJyaFSpUqlHttwFOf1HHwlloYUf+UUnHMvErjIN23btnVFP1Fo30fkaGwjS+MbORrbyNL4QqVKlbjpppt47bXXwrK8xYsX45xj8+bNpR7bcHyVagJwiwX8BtgVvDKMiIhIUhk5ciSbNm3i1FOPdFG6koXyVaq3gDSgjpmtBwYTuJg5zrkxBC5h1oXAVV2yCFwGT0REJGk45/jiiy/o2bMnxx57bJmXV2Jxds4Vd23WwtMd8OcyJxEREYlTzz33HOeee25YCjOEZ5+ziIjIQTZt2sSkSZOIh+s37Nmzp9SPLSgo4I033uDee+8lJSUlbJlUnEVEJOxGjhzJ008/7TtGyI4//vhSPe7111/nzDPPDGthBhVnERGJgJycHGrUqMG8efN8RwlJgwYNjmr+vLw8nnrqKfr06UPgLNbhpeIsIiIRkZKSQqNGjUqeMQ59+umnXH311REpzKCrUomIiIQsJyeH3r1706lTJ1q2bBmx9ag4i4iIhCAnJ4effvqJP//5z1SqVCmi69JmbRGRJJOfn8+cOXPIz89n8eLFEblk5ObNm8O+TJ+ys7Pp06cPjzzyCLVq1Yr4+lScRUSSzOjRo7n33nsjvp5E2d+cmZnJihUr6N+/f1QKM6g4i4gknV27dgEwfvx4Fi5cSKtWrSKynubNm0dkudG0Z88e+vXrx+DBg6lbt27U1qviLCKSpLp06UKNGjWS/sIXh7Nz505Wr17NI488Qp06daK6bh0QJiIiUkRmZiYDBgygcePGUS/MoM5ZRETkINu2bWPJkiU8+eSTVKlSxUsGFWcRkQjZt2+f7wjFys3N9R0hZuXn5zNkyBAee+wxb4UZVJxFRCJi2LBhDBw40HeMwzKziJ3dKl5lZGTw/fff88wzz3gfGxVnEZEIWL58Occccwz9+/f3HaVYJ510EuXLqwQU9uqrr/K3v/3Ne2EGFWcRkYipUaMG/fr18x1DSrB69WqmTJkSU1s6dLS2iIgkLeccU6dO5dZbb/Ud5SDqnEVEJCktXryYDz74gAEDBviOcgh1ziIiknQyMzNZtWoVffr08R2lWOqcRSTp3XDDDfz8889hXeamTZuoWbNmWJcp4TFnzhzGjRvHkCFDfEc5LBVnEUl6H374Ic2aNaN169ZhXe4FF1wQ1uVJ2a1evRrnHI8++qjvKEek4iwiAlx55ZUMHz7cdwyJoB9++IFJkyYxePDgmPi61JFon7OIiCS8H3/8keOPPz4uCjOoOIuISIKbOXMmU6dOpVGjRnFRmEHFWUREEtjnn39O/fr16du3b9wUZlBxFhGRBLVkyRIWLlxI/fr1fUc5airOIiKScD788EPMjL/85S++o5SKirOIiCSULVu2sHXrVk4++WTfUUpNX6USEZGE8fbbb9O0aVN69uzpO0qZqHMWEZGEsGfPHlJSUvjNb37jO0qZqXMWEZG4N3bsWBo0aMB1113nO0pYqDiLSELIz89n1KhR7Ny586gfm5eXF/5AEjXbtm3jxBNP5KKLLvIdJWxUnEUkIcybN4+//vWvpXqsmcX1wUPJbNSoUTRt2pQrrrjCd5SwUnEWkYSQn58PwPjx4+nWrdtRP75cOR2CE2/mz5/PJZdcQsuWLX1HCTu9GkUkoZQrV65UPxJfnnnmGTZt2pSQhRnUOYuISBxxzjFlyhRuu+02atSo4TtOxOjjooiIxI1//OMfVKtWLaELM6hzFpE4tm7dOmbNmgXA8uXLPaeRSHLO8eqrr3L33XcnxW4IFWcRiVt33HEHkydPPui+mjVr+gkjEfXWW2/RunXrpCjMoOIsInEsKyuLtm3b8tJLLwFQpUoVfSUqweTn5/PEE0/Qp08fUlJSfMeJGhVnEYlr1atXp3Xr1r5jSAQ45/jiiy+46qqrkqowgw4IExGRGJSbm0ufPn04//zzOe2003zHiTp1ziIiElNycnKYN28ed911F1WrVvUdxwsVZxE5oszMTDZv3uxt/RkZGaxcubLYadnZ2VSvXj3KiSSS9u3bR58+fRg0aBB169b1HccbFWcROaLzzz+fOXPm+I5xWJ07d/YdQcIkKyuLFStW0KdPn6QuzKDiLCIl2LJlCx06dOC2227zsv5FixZx6qmnHnb6eeedF8U0EimZmZn07duXQYMGcfzxx/uO452Ks4iU6OSTT+aWW27xsu709HTS0tK8rFuiY/fu3axcuZLBgwdz3HHH+Y4TE3S0toiIeLNv3z769+9Po0aNVJgLUecsIiJebN++nXnz5vHkk0+SmprqO05MUecsIiJRV1BQwNChQ2ndurUKczHUOYskoZdffpn77rsP51yJ82ZlZSXN+YwlOjZt2sS0adN48sknMTPfcWKSirNIEpo7dy55eXnce++9Jc5rZnTv3j0KqSRZ/POf/+See+5RYT4CFWeRJFWlShVGjhzpO4YkkbVr1zJhwgT69u3rO0rM07YqERGJuIKCAr788kvuuOMO31HigjpnERGJqGXLlvHmm28yePBg31HihjpnERGJmD179rB69WoGDhzoO0pcUecskgT279/P9ddfz5YtWwBYtWqV50SSDObPn8+//vUvHn/8cR38dZRUnEWSQEZGBhMmTOD000+nQYMGnHHGGZxzzjm+Y0kCW7lyJQUFBQwbNkyFuRRUnEWSSO/evenRo4fvGJLgZs2axfjx43nkkUf0HflS0qiJiEjYzJw5kzp16vDoo4+qMJeBRk5ERMJizpw5TJ48mcaNG2tTdhmpOIuISJl9+eWX1KxZkwEDBqgwh4H2OYvEsffff58pU6aUON/u3bujkEaS1apVq/j555+56KKLfEdJGCrOInFs2LBhzJ8/n1q1apU4b5MmTTj99NOjkEqSyccff0zjxo3529/+5jtKQlFxFoljzjkuu+wyJkyY4DuKJKEdO3awfv16rrjiCt9REo6Ks4iIHLVx48ZRt25d/vjHP/qOkpB0QJiIiByVrKwsADp06OA5SeJS5ywiIiF7/fXXOfbYY7nuuut8R0loKs4iZfDjjz/yww8/sHTpUhYsWBD19W/dupWGDRtGfb2SnLZu3UqTJk3UMUeBirNIGdx5553Mnj3ba4Zu3bp5Xb8khxdeeIHjjz+eq666yneUpKDiLFIGubm5dO3aldtvv53zzz/fS4batWt7Wa8kj7lz59KxY0eaN2/uO0rSUHEWKaNKlSpRs2ZNjjvuON9RRMLu+eefp0WLFlx22WW+oyQVFWcRETmEc45PPvmEHj16UL16dd9xko6+SiUiIod4+eWXqV69ugqzJ+qcRUTkv5xzvPzyy9x+++265KNHGnkREfmvDz74gNatW6swe6bOWUREKCgoYNiwYfTt25cKFSr4jpP0QvpoZGadzWyJmS03s37FTK9hZh+Z2RwzW2Bm/xf+qCIiEgnOOaZNm8ZVV12lwhwjSizOZpYCjAIuB04Dfm9mpxWZ7c/AQufcGUAa8JSZVQxzVhERCbP8/Hz69OnDmWeeya9//WvfcSQolM75HGC5c26lcy4HeBsoeooYB1Q3MwOqAduBvLAmFRGRsMrJyWHVqlXceeed1KhRw3ccKSSUfc4NgHWFbq8H2hWZ53lgApABVAducM4VFF2Qmd0J3AlQr1490tPTD5q+d+/eQ+6T8NDYHllubi779+8/6sft2bOHrVu3anwjSGMbGTk5ObzwwgtceeWVbNiwgQ0bNviOlHDK8toNpThbMfe5IrcvA2YDFwMnAZ+Z2dfOud0HPci5F4EXAdq2bevS0tIOWkh6ejpF75Pw0NgeXk5ODg0bNmTr1q2levx5551HtWrVNL4Rotdu+O3bt4/ly5fzzDPPsHLlSo1vhJTltRtKcV4PNCp0uyGBDrmw/wOGO+ccsNzMVgGnAD+UKpVIFGVnZ7N161auvPLKUv1H6tKlCxs3bgx/MJEIyMrKom/fvvTr148GDRqwcuVK35GkGKEU5x+BFmZ2IrABuBH4Q5F51gIdga/NrB7QEtBfXOJKWloa999/f6keq+Is8WDv3r0sXbqUhx56SOeCj3ElHhDmnMsD7gEmA4uAd51zC8zsLjO7KzjbY8B5ZjYP+ALo65zbFqnQIiJydHJzc+nTpw8NGzZUYY4DIZ2ExDk3CZhU5L4xhX7PAC4NbzQREQmHHTt2MHPmTJ555hkqVarkO46EQOdnExFJYM45Hn/8cc4++2wV5jii03dKwlixYgVdu3YlMzPzqB5XUHDIt/5EEsKWLVv47LPPGDFiBIHTUEi8UHGWhLF48WIWL15M165dj3qfWoUKFbjqqqLn1hGJb2+88QZ//OMfVZjjkIqzJJyHHnqIs88+23cMEW82bNjAu+++S69evXxHkVLSPmcRkQRSUFDAV199xd133+07ipSBOmcRkQSxcuVKxo4dy5AhQ3xHkTJS5ywikgB27drFmjVrGDx4sO8oEgYqziIicW7RokUMGTKEtLQ0XY85Qag4i4jEsRUrVpCfn8/w4cN1VHYCUXEWEYlTc+fO5ZVXXuG0004jJSXFdxwJIxVnEZE4NGvWLKpXr86QIUMoV05v5YlGf1ERkTizcOFCJk2aRNOmTVWYE5T+qiIicWTatGlUrFiRQYMGaR9zAtP3nCWuffzxx3z77bcALF++3HMakcjKyMjg+++/54EHHlBhTnAqzhLXHnjgAZYsWUL58oGXcp06dWjQoIHnVCLhN3nyZOrUqUPv3r19R5Eo0GZtiWsFBQXccMMN5OTkkJOTw9atW6lfv77vWCJhtXfvXlatWkWbNm18R5EoUecsIhLD/vOf/1CtWjXuuusu31EkitQ5i4jEqOzsbPLz8+nUqZPvKBJl6pxFRGLQv//9b1JTU7n22mt9RxEPVJwlJkybNo2MjIyjftzu3bsjkEbEr82bN9OkSRPat2/vO4p4ouIs3u3atYu0tDScc6V6fO3atcOcSMSfl19+mZo1a6pjTnIqzuJdTk4OzjkGDRrETTfddNSPP+mkkyKQSiT6fv75Zzp27MiJJ57oO4p4puIsMeP444/nlFNO8R1DxIsXXniBhg0bcuaZZ/qOIjFAxVlExLMJEyZw8803U7VqVd9RJEboq1QiIh699tprVKtWTYVZDqLOWaJm/fr1xR5dvX37dg9pRPxyzvHiiy/Ss2dPXYtZDqHiLFGxcuXKEg/cSk1NjVIaEf8mTpxIq1atVJilWCrOEhU7duwAoHfv3rRt2/aQ6RUqVKBz587RjiUSdQUFBQwbNowHHniAypUr+44jMUrFWaLqggsuoFu3br5jiHjhnGPGjBl07dpVhVmOSAeEiYhEQV5eHn379uXkk0+mdevWvuNIjFPnLCISYbm5uSxevJjbbruNOnXq+I4jcUCds4hIBOXk5NCnTx9q1Kihk+xIyNQ5i4hEyP79+1m+fDl//etfady4se84EkfUOYuIRMC+ffvo3bs31atXp2nTpr7jSJxR5ywiEmaZmZksWrSIBx98kOOOO853HIlD6pxFRMIoPz+ffv360ahRIxVmKTV1ziIiYbJr1y6mT5/OU089RcWKFX3HkTimzllEJExGjhxJu3btVJilzNQ5S9isWrWKm2++maysrEOmFXefSKLYtm0bEydOZMiQIb6jSIJQcZawmTNnDtOnT6dDhw7UqFHjkOlnnXUW7dq185BMJLLefPNNbr31Vt8xJIGoOEvYPfvsszo9oSSFjRs38sYbb9CnTx/fUSTBaJ+ziEgp5Ofn8/XXX3PPPff4jiIJSMVZROQorV69mgEDBnD99ddTpUoV33EkAak4i4gchR07drB27Voee+wx31Ekgak4i4iEaMmSJQwZMoTzzz9fX5eSiFJxFhEJwfLly8nLy2PEiBGkpKT4jiMJTsVZRKQECxYs4JVXXuGUU06hfHl9yUUiT8VZROQIfv75ZypXrszQoUPVMUvUqDiLiBzG8uXLGT9+PM2aNaNcOb1dSvTo1SYiUoxvv/2W3NxcHn74YczMdxxJMtp5IiX66KOPWLp0aYnzzZs3LwppRCJv69atfP311/Tt21eFWbxQcZYSXXvtteTk5IQ0b2pqKnXr1o1wIpHI+fzzz6lSpQr9+vXzHUWSmDZrS4ny8vLo3bs3u3fvLvFnx44d1K9f33dkkVLJzs5m2bJlnHfeeb6jSJJT5ywhqVSpEtWrV/cdQyRiJkyYQLly5bj77rt9RxFR5ywikp2dTU5ODl27dvUdRQRQ5ywiSe7tt98G4MYbb/ScROR/VJwT2KZNm/57BPWcOXPIzc0t1XKcc+GMJRIzNm7cSJMmTTj33HN9RxE5iIpzAuvevTuff/55WJZ1zDHHhGU5IrHi1VdfJTU1VR2zxCQV5wS2d+9ezj77bJ555hl++uknzjrrrFItJyUlpdSPFYlFM2fOpGPHjjRu3Nh3FJFiqTgnuGOPPZbzzz+f3Nxczj//fN9xRLwbO3YstWvXpm3btr6jiByWirOIJI3x48dz4403UqVKFd9RRI5IX6USkaTw9ttvU7VqVRVmiQvqnEUkoTnneOGFF+jZs6euxSxxQ52ziCS0KVOm8Ktf/UqFWeKKirOIJCTnHEOHDqV9+/a0b9/edxyRo6KPkiKScAoKCvjpp5/o3LkzVatW9R1H5KipcxaRhJKfn8+AAQNo0KABbdq08R1HpFTUOYtIwsjLy2PZsmV0796dE044wXcckVJT5ywiCSE3N5e+fftSqVIlTj/9dN9xRMpExTmBzJ07lyZNmlCvXj3q1avHzJkzMTPfsUQiLicnh6VLl/LnP/+ZZs2a+Y4jUmbarJ1AFi9ezNq1a7n++uupVasWAL/73e88pxKJrJycHHr37s39999P06ZNfccRCQsV5wQ0ePBgTjvtNN8xRCIuOzubuXPn8uCDD1KnTh3fcUTCRpu1RSQuOefo378/jRs3VmGWhKPOWUTizp49e/jyyy8ZOXIkFSpU8B1HJOzUOYtI3Hnqqac477zzVJglYalzjgG5ubn06NGDLVu2lGk5mzdvDlMikdi0fft23n//fR5++GHfUUQiKqTibGadgeeAFOBl59zwYuZJA54FKgDbnHMdwpYywa1fv5633nqL5s2bU69evVIvp0aNGlx55ZWceOKJYUwnEjveeecd/vCHP/iOIRJxJRZnM0sBRgGdgPXAj2Y2wTm3sNA8NYF/AJ2dc2vNrG6E8ia0QYMG0aNHD98xRGLO5s2beemllxg0aJDvKCJREco+53OA5c65lc65HOBt4Koi8/wB+MA5txbAOVe27bMiIkH5+fl8++233H///b6jiERNKMW5AbCu0O31wfsKOxk41szSzWyWmd0SroAikrzWrVvHCy+8wG9/+1tdXUqSSij7nIs7/6MrZjltgI5AKvCdmc1wzi09aEFmdwJ3AtSrV4/09PSDFrJ3795D7ksGGzduBGDRokURe/7JOrbRovENv127drF+/XpuvPFGvvrqK99xEpZeu5FTlrENpTivBxoVut0QyChmnm3OuUwg08ymAWcABxVn59yLwIsAbdu2dWlpaQctJD09naL3Jarp06fz3nvvAYE3IYBTTz01Ys8/mcbWB41veC1fvpzx48fz5JNP8s0332hsI0iv3cgpy9iGUpx/BFqY2YnABuBGAvuYC/sQeN7MygMVgXbAM6VKlCRGjhzJhx9+SLVq1QCoU6cOLVu29JxKxL8VK1awf/9+Ro4cSfny+ranJKcSX/nOuTwzuweYTOCrVGOdcwvM7K7g9DHOuUVm9ikwFygg8HWr+ZEMHu+cc7Rq1YrZs2f7jiISM5YsWcIrr7zCsGHDVJglqYX06nfOTQImFblvTJHbI4GR4YsmIslkzpw5pKam8vjjj5OSkuI7johXOn2niHi3du1axo0bR/PmzVWYRdDpO0XEs++//57U1FQee+wxzIr7cohI8lFxjpL8/HzGjx/Pnj17gECnIJLsdu7cydSpU+nXr58Ks0ghKs5RMnPmTK699tqD7uvUqZOnNCL+Hfj+Z//+/f0GEYlBKs5Rsn//fgD+/e9/c9555wFwwgkn+Iwk4k1OTg6LFy/mrrvu8h1FJCapOEfZ8ccfT9OmTX3HEPFm0qRJ7Nu3T4VZ5Ah0tLaIRE12djb79+/nmmuu8R1FJKapcxaRqHjvvffIzs6me/fuvqOIxDwVZxGJuPXr19O4cWPOOecc31FE4oKKc5R89tlnAFSpUsVzEpHo+te//oWZcdNNN/mOIhI3VJyj4Omnn2bIkCF0795dnYMkle+//56LLrqIBg2KXgJeRI5EB4RF2JgxY+jVqxfXXXcdY8eOpVw5DbkkhzfeeIMNGzaoMIuUgjrnCPrnP//J3XffTdeuXfnXv/6lq+xI0nj//fe59tprSU1N9R1FJC6pjYuQd999l9tuu41LLrmEcePGUbFiRd+RRKLigw8+oGrVqirMImWgVi4CJkyYwE033cT555/P+PHjqVy5su9IIhHnnGP06NH07NlTH0ZFykidc5hNmTKF6667jrPOOouJEydStWpV35FEouKrr77i9NNPV2EWCQMV5zCaNm0aV199NaeeeiqffPIJxxxzjO9IIhHnnGPo0KG0bt2aDh06+I4jkhBUnMPk+++/54orrqBp06ZMmTKFWrVq+Y4kEnHOOebOnUunTp2oWbOm7zgiCUPFOQxmz55N586dqVevHp9//jl169b1HUkk4goKChg0aBDHHnusvr8vEmY6IKyMFi5cSKdOnahevTpffPEF9evX9x1JJOLy8/NZuXIlN9xwA40bN/YdRyThqHMug2XLltGxY0cqVKjA1KlTadKkie9IIhGXl5dHv379cM7RqlUr33FEEpI651Jas2YNHTt2JC8vj6+++ormzZv7jiQScbm5uSxdupS77rqLk046yXcckYSlzrkUMjIyuPjii9mzZw9TpkzhtNNO8x1JJOLy8vLo06cPlStXVmEWiTB1zkdpy5YtdOzYkS1btvD5559z5pln+o4kEnH79u1j1qxZPPjgg/omgkgUqHM+Ctu3b+fSSy9lzZo1fPzxx7Rr1853JJGIc84xcOBAmjRposIsEiXqnEO0e/duOnfuzKJFi5g4cSIXXnih70giEbd3716mTJnCiBEjdOEWkShS5xyCzMxMrrjiCn7++Wfee+89OnXq5DuSSFQ899xztG/fXoVZJMr0Py4E119/PdOnT+ett96iW7duvuOIRNzOnTt58803GThwoO8oIklJnXMJsrOzmTRpEr169eL666/3HUckKt577z1+//vf+44hkrTUOYeodu3aviOIRNzWrVsZNWoUDz/8sO8oIklNnbOIAIETjMyYMYNevXr5jiKS9FScRYQNGzbQu3dvunbtSvXq1X3HEUl6Ks4iSW7r1q1s2LCBxx9/HDPzHUdEUHEWSWqrVq1iyJAhtG7dmtTUVN9xRCRIB4SJJKkVK1awf/9+Ro4cScWKFX3HEZFC1DmLJKEVK1YwevRoTj75ZBVmkRikzlkkycyfP5+UlBRGjBhBSkqK7zgiUgx1ziJJZOPGjbz55pu0bNlShVkkhqlzFkkSM2fOBGDo0KE6KlskxqlzFkkCmZmZTJ48mTZt2qgwi8QBdc4iCe7rr78mKytLF7EQiSPqnEUSWF5eHgsXLuTSSy/1HUVEjoI6Z5EENXnyZLZv384f//hH31FE5CipcxZJQFlZWezbt0+XfRSJU+qcRRLM+PHj2b59O7fddpvvKCJSSirOIglkzZo1NGrUiKuvvtp3FBEpAxVnkQTx1ltvkZOTQ48ePXxHEZEyUnEWSQDffvstaWlpnHDCCb6jiEgY6IAwkTj39ttvs2HDBhVmkQSizlkkjr333ntcffXVVK5c2XcUEQkjdc4icWrixIlUqlRJhVkkAalzFolDo0eP5tZbbyU1NdV3FBGJAHXOInFm+vTptGzZUoVZJIGpOIvECeccjz/+OC1atODiiy/2HUdEIkjFWSQOOOdYvHgxHTp04LjjjvMdR0QiTMVZJMYVFBQwePBgKlSowHnnnec7johEgYqzSAwrKChg1apVXHPNNTRv3tx3HBGJEhVnkRiVn59P//792b9/P61bt/YdR0SiSF+lKsbHH3/MiBEjcM6Rn5/vO44koby8PJYsWcKdd97JSSed5DuOiESZOudifPTRR8yYMYOKFSuSmprKpZdeSqdOnXzHkiRRUFBAnz59qFixogqzSJJS53wYtWrV4osvvvAdQ5LM/v37+f7773nooYeoWbOm7zgi4ok6Z5EYMnjwYJo2barCLJLk1DmLxICsrCwmTpzI0KFDSUlJ8R1HRDxT5ywSA0aNGsWFF16owiwigDpnEa92797Nq6++Su/evX1HEZEYos5ZxBPnHP/5z3+4+eabfUcRkRij4iziwS+//MLAgQPp0aMHtWvX9h1HRGKMirNIlO3fv58ffviBfv36+Y4iIjFKxVkkijZu3MgDDzzApZdeyjHHHOM7jojEKBVnkSjZsmULGzZsYMSIEToqW0SOSMVZJArWrFnDkCFD+NWvfkWVKlV8xxGRGKevUolE2KpVq8jKymLkyJFUqlTJdxwRiQPqnEUiaM2aNfz973/n5JNPVmEWkZCpcxaJkEWLFpGfn88TTzxB+fL6ryYioVPnLBIB27Zt47XXXuPUU09VYRaRo6Z3DZEw+/nnn8nOzmb48OGYme84IhKHQuqczayzmS0xs+VmdtgzJ5jZ2WaWb2bXhi9idCxevJjp06czffp0Nm3a5DuOxKl9+/YxadIkfvOb36gwi0ipldg5m1kKMAroBKwHfjSzCc65hcXMNwKYHImgkZSRkcGpp5560H0nnXSSpzQSr6ZPn/7f03KKiJRFKJu1zwGWO+dWApjZ28BVwMIi890LvA+cHdaEUbBnzx4A+vXrx0UXXQRA8+bNfUaSOJOfn8/8+fO54447fEcRkQQQSnFuAKwrdHs90K7wDGbWAPgtcDFxWJwPaNWqFZdeeqnvGBJnvvjiCz777DOGDx/uO4qIJIhQinNxO85ckdvPAn2dc/lH2s9mZncCdwLUq1eP9PT0g6bv3bv3kPuiYe3atQAsXLjQy/qjwdfYJrrs7Gxmz55N+/btNb4RotduZGl8I6csYxtKcV4PNCp0uyGQUWSetsDbwcJcB+hiZnnOufGFZ3LOvQi8CNC2bVuXlpZ20ELS09Mpel80LFmyBIDTTjvNy/qjwdfYJrKJEyeSkZFB//79Nb4RpLGNLI1v5JRlbEMpzj8CLczsRGADcCPwh8IzOOdOPPC7mb0GTCxamEUSycqVK2nYsCFdu3b1HUVEElCJxdk5l2dm9xA4CjsFGOucW2BmdwWnj4lwRpGYMm7cOHbv3s3tt9/uO4qIJKiQTkLinJsETCpyX7FF2Tl3a9ljicSmadOm0aFDB+rWres7iogkMJ2+UyREH3zwARkZGSrMIhJxOn2nSAjGjRtH165dSU1N9R1FRJKAOmeREnz22WdUqFBBhVlEokads8gRjB49mu7du1OtWjXfUUQkiSRNcV67di1du3Zl7969h0zLycnxkEhi3axZszjppJNUmEUk6pKmOC9dupR58+Zx6aWXUq9evUOmV65c+b/n1Zbk5pxj5MiR3HzzzbRp08Z3HBFJQklTnA948MEHad++ve8YEqOcc6xYsYJzzz2X+vXr+44jIklKB4SJBDnneOSRR8jNzeWCCy7wHUdEkljSdc4ixSkoKGDNmjVceeWVh1zbW0Qk2tQ5S9IrKChg4MCB7Nmzh7POOst3HBGRxO6cx4wZw6effgrAli1bPKeRWJSfn8/ChQu54447aNasme84IiJAgnfOo0aN4ssvv2T16tVkZWVxwQUX0LJlS9+xJEY45+jXrx8VKlRQYRaRmJLQnTPAJZdcwvvvv+87hsSYnJwcvv76awYNGkSNGjV8xxEROUhCd84ih/Poo4/SrFkzFWYRiUkJ3zmLFJadnc0HH3zAo48+Srly+mwqIrFJ706SVMaMGUNaWpoKs4jENHXOkhT27NnDiy++SK9evXxHEREpkdoHSXjOOT766CNuueUW31FEREKi4iwJbceOHfTt25ff//73HHfccb7jiIiERMVZEta+ffuYNWsWAwYMwMx8xxERCZmKsySkzZs306tXLzp06EDNmjV9xxEROSoqzpJwtmzZwoYNG3jiiSeoUKGC7zgiIkct7o/Wnj17NsuWLSt22q5du6KcRnxbv349I0aM4IknniA1NdV3HBGRUon74ty5c2c2b9582OmXXXZZFNOIT2vWrGHv3r2MHDmSypUr+44jIlJqcV+cs7Oz6d69O3379i12eosWLaKcSHzIyMjg2WefZcSIEVSsWNF3HBGRMon74gxQu3ZtTj/9dN8xxJOlS5eSnZ2tfcwikjB0QJjEtV27dvHyyy9z+umnqzCLSMJIiM5ZktPcuXPZvn07I0aM0PeYRSShqHOWuJSbm8vEiRO58MILVZhFJOGoc5a488MPP7Bu3ToGDBjgO4qISESoc5a4UlBQwNy5c7nmmmt8RxERiRh1zhI30tPTWbZsGXfccYfvKCIiEaXOWeLC7t27yc7OpmfPnr6jiIhEnDpniXmffPIJK1as4J577vEdRUQkKlScJaYtW7aMhg0bcvnll/uOIiISNdqsLTFr/PjxpKen8+tf/9p3FBGRqFLnLDEpPT2d9u3bU6dOHd9RRESiTp2zxJyPPvqI9evXqzCLSNJS5ywx5Z133qFbt25UqVLFdxQREW/UOUvM+OqrryhfvrwKs4gkPXXOEhPGjBnDDTfcwLHHHus7ioiId+qcxbt58+bRuHFjFWYRkSAVZ/Hqqaeeolq1anTp0sV3FBGRmKHN2uKFc461a9fSpk0bTjzxRN9xRERiijpniTrnHEOHDmXnzp2kpaX5jiMiEnNUnCWqnHOsWbOGyy+/nDPOOMN3HBGRmKTiLFFTUFDAgw8+yI4dO2jTpo3vOCIiMUv7nCUq8vPzmT9/Prfffrv2MYuIlECds0Scc46BAwdSvnx5FWYRkRCoc5aIys3N5csvv2TgwIFUr17ddxwRkbigzlkiatiwYTRr1kyFWUTkKKhzlojYt28f77zzDg8++CDlyukzoIjI0dC7pkTE2LFjufjii1WYRURKQZ2zhFVmZibPP/88ffv29R1FRCRuqa2RsHHOMWnSJG699VbfUURE4pqKs4TFzp076dWrF7/73e+oV6+e7zgiInFNxVnKLDs7mzlz5jBo0CDtYxYRCQO9k0qZbNu2jQceeIB27dpRq1Yt33FERBKCDgiTUtu6dSsbNmxg+PDhVK5c2XccEZGEoc5ZSmXjxo088sgjtGjRQicYEREJM3XOctTWrVvHzp07GTlyJKmpqb7jiIgkHHXOclS2bNnCk08+SYsWLVSYRUQiRJ2zhGz58uXs2rWLkSNHUrFiRd9xREQSljpnCUlmZiYvvvgirVq1UmEWEYkwdc5SogULFrBhwwZGjBiBmfmOIyKS8OKyc96xYwfbtm1j27ZtFBQU+I6T0PLz85kwYQIdO3ZUYRYRiZK465xffvll7rjjjoPuq1Chgqc0iW3WrFksWbKE/v37+44iIpJU4q44r1+/HoC///3vAJQrV46rr77aY6LElJ+fz7x58+jRo4fvKCIiSSfuivMB99xzj+8ICeubb75h7ty5/OlPf/IdRUQkKcXlPmeJnF27dpGVlcXdd9/tO4qISNKK285Zwu+zzz5jwYIF3Hfffb6jiIgkNRVnAWDx4sU0aNCATp06+Y4iIpL0Yr445+XlceGFF7J69WoA9uzZ4zdQApo4cSLr1q3TpmwRkRgR88U5MzOT7777jnbt2tGqVSsATjnlFM+pEseXX37JueeeS9euXX1HERGRoJgvzgfccMMN3H///b5jJJRPP/2UTZs2cdFFF/mOIiIihcRNcZbwevfdd+nSpQvVqlXzHUVERIrQV6mS0IwZMwBUmEVEYlRIxdnMOpvZEjNbbmb9ipl+k5nNDf5MN7Mzwh9VwuGll16iWbNmXH/99b6jiIjIYZS4WdvMUoBRQCdgPfCjmU1wzi0sNNsqoINzboeZXQ68CLQrbahPPvmE5557DoDc3NzSLkaKWLp0Kccffzx169b1HUVERI4glM75HGC5c26lcy4HeBu4qvAMzrnpzrkdwZszgIZlCTVu3DimTp3Kzp07yczMpH379lx44YVlWWTSe++993DO0a1bN99RRESkBKEcENYAWFfo9nqO3BXfDnxS3AQzuxO4E6BevXqkp6cfNH3v3r2kp6ezceNGjj32WIYPH/7faXv27DlkfimZc45ffvmFE044gY0bN7Jx40bfkRLSgdeuhJ/GNrI0vpFTlrENpTgXdxFfV+yMZhcRKM7ti5vunHuRwCZv2rZt69LS0g6anp6eTlpaGq+//jqVKlWi6HQ5Os45hg8fTqdOnahTp47GM4IOvHYl/DS2kaXxjZyyjG0om7XXA40K3W4IZBSdycxaAS8DVznnfilVGgkb5xxr166lU6dOtG3b1nccERE5CqEU5x+BFmZ2oplVBG4EJhSewcwaAx8A3Z1zS8MfU46Gc47BgwezZcsWFWYRkThU4mZt51yemd0DTAZSgLHOuQVmdldw+hjgIaA28A8zA8hzzqkqeFBQUMCcOXO4/fbbadKkie84IiJSCiGdIcw5NwmYVOS+MYV+7wn0DG80KY3Bgwdz/fXXqzCLiMQxnb4zQeTl5TFlyhT69etH1apVfccREZEy0Ok7E8QTTzxB8+bNVZhFRBKAOuc4t3//ft544w369+9PcH+/iIjEOXXOce6f//wnnTp1UmEWEUkg6pzjVFZWFk8//TQDBw5UYRYRSTDqnOOQc44pU6Zw++23qzCLiCQgFec4s3v3bu6//366devGCSec4DuOiIhEgIpzHMnMzGTevHkMGjSIlJQU33FERCRCVJzjxPbt2+nduzetW7emTp06vuOIiEgE6YCwOLBt2zY2bNjA448/ru8xi4gkAXXOMW7z5s08/PDDNGvWjBo1aviOIyIiUaDOOYZt2LCBX375hREjRqhjFhFJIuqcY9T27dsZPnw4LVq0UGEWEUky6pxj0KpVq9i8eTNPP/00FSpU8B1HRESiTJ1zjNm/fz+jR4/mrLPOUmEWEUlS6pxjyOLFi1m+fDlPPPGE7ygiIuKROucY4ZxjwoQJXH755b6jiIiIZ+qcY8Ds2bOZPXs2ffr08R1FRERigDpnz/Lz85k3bx633HKL7ygiIhIj1Dl7NGPGDGbMmMF9993nO4qIiMQQdc6e7Nixg8zMTP7617/6jiIiIjFGnbMHU6dO5aeffuKBBx7wHUVERGKQinOULViwgAYNGnDxxRf7jiIiIjFKm7WjaPLkyUydOpWWLVv6jiIiIjFMnXOUTJ06lbZt23LZZZf5jiIiIjFOnXMUTJ06lVWrVlG7dm3fUUREJA6oc46wcePG0alTJ+1jFhGRkKlzjqCffvqJ3Nxcatas6TuKiIjEERXnCHnllVeoW7cuf/jDH3xHERGROKPiHAGrV6+mVq1aNGzY0HcUERGJQyrOYfb3v/+d3bt389vf/tZ3FBERiVMqzmG0efNmTjnlFFq1auU7ioiIxDEV5zBwzjFixAhWrlxJp06dfMcREZE4p69SlZFzjrVr13LJJZfQpk0b33FERCQBqHMuA+ccjz76KBkZGSrMIiISNuqcS6mgoICffvqJ2267jUaNGvmOIyIiCUSdcyk9+uijpKSkqDCLiEjYqXM+Svn5+Xz88cf07duX1NRU33FERCQBqXM+Sk8//TQtWrRQYRYRkYhR5xyi3Nxcxo4dywMPPICZ+Y4jIiIJTJ1ziP7973/TqVMnFWYREYk4dc4l2LdvH8OHD2fw4MEqzCIiEhXqnI+goKCAqVOncscdd6gwi4hI1Kg4H8bevXu5//77ueSSS2jQoIHvOCIikkRUnIuRmZnJwoULGTRoEBUrVvQdR0REkoyKcxE7duygd+/enHLKKRx33HG+44iISBLSAWGF/PLLL6xfv55hw4ZxzDHH+I4jIiJJSp1z0LZt23jooYc48cQTqVmzpu84IiKSxNQ5A5s2bWLTpk2MGDGCatWq+Y4jIiJJLuk75927dzN06FBOPvlkFWYREYkJSd05r1mzhrVr1/L0009ToUIF33FERESAJO6c8/LyGD16NOecc44Ks4iIxJSk7JyXLVvG/PnzGT58uO8oIiIih0i6ztk5x4QJE+jWrZvvKCIiIsWKic55+/btnHPOOWzZsoXy5cuzd+9eTjjhhLCvZ968eXz33Xf06tUr7MsWEREJl5gozhkZGaxYsYJzzjmHdu3aAXDuueeGdR15eXnMmzePnj17hnW5IiIi4RYTxfmALl26MHjw4LAv98cff+TLL7+kT58+YV+2iIhIuCX8Pudt27aRlZVF7969fUcREREJSUIX52nTpvHSSy/RoUMHXY9ZRETiRsIW53nz5nHCCSfQr18/31FERESOSkIW5y+++ILPP/+cFi1aqGMWEZG4E1MHhIXDF198wRlnnEHHjh19RxERESmVhOqcv/nmG5YvX06dOnV8RxERESm1hOmc33vvPS666CLat2/vO4qIiEiZJETnvGDBArKysqhdu7bvKCIiImUW98X5tddeIzU1lVtuucV3FBERkbCI6+KckZFBtWrVaNasme8oIiIiYRO3xXn06NFkZGRw7bXX+o4iIiISVnFZnLdt28ZJJ51E27ZtfUcREREJu7grzk8//TQLFy7k0ksv9R1FREQkIuLmq1TOOdasWUOHDh1o06aN7zgiIiIRExeds3OOYcOGsW7dOhVmERFJeDHfOTvn+OGHH7j11ltp0KCB7zgiIiIRF/Od87Bhw0hJSVFhFhGRpBGznXNBQQHjx4+nV69eVK5c2XccERGRqInZzvn555/n5JNPVmEWEZGkE1JxNrPOZrbEzJabWb9ippuZ/b/g9LlmdlZpA+Xm5jJq1CjuvfdefvWrX5V2MSIiInGrxOJsZinAKOBy4DTg92Z2WpHZLgdaBH/uBEaXNtC4ceO47LLLMLPSLkJERCSuhdI5nwMsd86tdM7lAG8DVxWZ5yrgdRcwA6hpZiccbZipU6dy44030rx586N9qIiISMIIpTg3ANYVur0+eN/RzlOiNm3aUK5czO4GFxERiYpQjtYubvuyK8U8mNmdBDZ7U69ePdLT0wHIyspi+PDh1K9f/7/3SXjt3btXYxtBGt/I0dhGlsY3csoytqEU5/VAo0K3GwIZpZgH59yLwIsAbdu2dWlpaf+d1qVLF9LT0yl8n4SPxjayNL6Ro7GNLI1v5JRlbEPZhvwj0MLMTjSzisCNwIQi80wAbgketf0bYJdzbmOpEomIiCS5Ejtn51yemd0DTAZSgLHOuQVmdldw+hhgEtAFWA5kAf8XucgiIiKJzZw7ZNdwdFZsthVYU+TuOsA2D3GSgcY2sjS+kaOxjSyNb+QUN7ZNnHPHlfRAb8W5OGY20znX1neORKSxjSyNb+RobCNL4xs5ZRlbfW9JREQkxqg4i4iIxJhYK84v+g6QwDS2kaXxjRyNbWRpfCOn1GMbU/ucRUREJPY6ZxERkaQX9eIczctPJqMQxvem4LjONbPpZnaGj5zxqKSxLTTf2WaWb2bXRjNfvAtlfM0szcxmm9kCM/sq2hnjVQjvCzXM7CMzmxMcW52rIkRmNtbMtpjZ/MNML11Nc85F7YfASUxWAM2AisAc4LQi83QBPiFwvu7fAN9HM2M8/4Q4vucBxwZ/v1zjG76xLTTfVAIn5rnWd+54+QnxtVsTWAg0Dt6u6zt3PPyEOLYDgBHB348DtgMVfWePhx/gQuAsYP5hppeqpkW7c47a5SeTVInj65yb7pzbEbw5g8B50KVkobx2Ae4F3ge2RDNcAghlfP8AfOCcWwvgnNMYhyaUsXVAdTMzoBqB4pwX3ZjxyTk3jcB4HU6palq0i3PULj+ZpI527G4n8IlOSlbi2JpZA+C3wJgo5koUobx2TwaONbN0M5tlZrdELV18C2VsnwdOJXDBonnAX51zBdGJl/BKVdNCuSpVOIXt8pNSrJDHzswuIlCc20c0UeIIZWyfBfo65/IDDYgchVDGtzzQBugIpALfmdkM59zSSIeLc6GM7WXAbOBi4CTgMzP72jm3O8LZkkGpalq0i3PYLj8pxQpp7MysFfAycLlz7pcoZYt3oYxtW+DtYGGuA3Qxszzn3PioJIxvob43bHPOZQKZZjYNOANQcT6yUMb2/4DhLrCTdLmZrQJOAX6ITsSEVqqaFu3N2rr8ZGSVOL5m1hj4AOiujuOolDi2zrkTnXNNnXNNgfeAP6kwhyyU94YPgQvMrLyZVQHaAYuinDMehTK2awlskcDM6gEtgZVRTZm4SlXToto5O11+MqJCHN+HgNrAP4IdXp7TSe9LFOLYSimFMr7OuUVm9ikwFygAXnbOFfv1FfmfEF+7jwGvmdk8Apth+zrndKWqEJjZW0AaUMfM1gODgQpQtpqmM4SJiIjEGJ0hTEREJMaoOIuIiMQYFWcREZEYo+IsIiISY1ScRUREYoyKs4iISIxRcRYREYkxKs4iIiIx5v8DjBI/r3uoNGQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist.history[\"accuracy\"],'r', marker='.', label=\"Train Accuracy\")\n",
    "ax.plot(run_hist.history[\"val_accuracy\"],'b', marker='.', label=\"Test Accuracy\")\n",
    "ax.legend()\n",
    "\n",
    "y_pred_prob = model.predict(X_test_norm)\n",
    "plot_roc(y_test, y_pred_prob, 'NN')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Este modelo apresentou melhores resultados para números menores de épocas proximas de 100 e taxas de aprendizado entre 0.003 e 0.001. Para 1500 iterações o modelo apresenta overfit, onde sua acuracia para o conjunto de teste diminui e o loss aumenta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
